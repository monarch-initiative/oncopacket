{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Oncopacket","text":"<p>Oncopacket is a Python library designed to harmonize genetic and clinical cancer data  into GA4GH Phenopackets, an ISO standard for representing  clinical case data. This library enables interoperability and standardized data  representation for cancer genomics research.</p> <p>Oncopacket transforms cancer data into the GA4GH Phenopacket Schema, facilitating integration with  upstream cancer data sources and downstream analytical tools. Currently, Oncopacket primarily uses  the Cancer Data Aggregator (CDA) Python library to extract cohorts  from NCI's Cancer Research Data Commons (CRDC).</p>"},{"location":"#core-features","title":"Core Features","text":"<ul> <li>Data Integration: Extracts demographic, mutation, morphology, diagnosis, intervention, and survival data from NCI cancer data</li> <li>Data Standardization: Converts cancer data to GA4GH Phenopackets format</li> <li>Ontology Mapping: Maps cancer terms to standardized ontologies like NCIT and UBERON</li> <li>Analysis Support: Enables downstream cohort analysis, survival studies, and other statistical/ML applications</li> </ul>"},{"location":"#main-components","title":"Main Components","text":"<ul> <li>CDA Module: Factories and importers to transform CDA data into phenopacket components</li> <li>Model Module: Core data structures representing individuals, diseases, and genetic mutations</li> <li>Mapping Tools: Utilities to map between different oncology terminologies</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To get started with Oncopacket, follow these steps:</p> <ol> <li>Install Oncopacket</li> <li>See our examples in the Jupyter notebooks</li> <li>Explore the API documentation</li> </ol>"},{"location":"#project-status","title":"Project Status","text":"<p>While Oncopacket currently focuses on data from NCI's Cancer Research Data Commons, the  modular code can be extended for use with other data sources. The software is designed  to accurately represent existing data from upstream sources without imputing missing  records.</p>"},{"location":"#feedback","title":"Feedback","text":"<p>The best place to leave feedback, ask questions, and report bugs is the Oncopacket Issue Tracker.</p>"},{"location":"installation/","title":"Installation","text":"<p>The package is designed to work with Python 3.8 or later.</p>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<p>Oncopacket has the following main dependencies: - <code>phenopackets</code> (GA4GH Phenopacket Schema) - <code>cdapython</code> (Cancer Data Aggregator Python library) - <code>hpo-toolkit</code> (Tools for working with the Human Phenotype Ontology) - <code>requests</code> (For API communication)</p>"},{"location":"installation/#installation_1","title":"Installation","text":""},{"location":"installation/#1-create-a-virtual-environment-recommended","title":"1: Create a virtual environment (recommended)","text":"<p>First, create and activate a virtual environment, for example:</p> <pre><code>python3 -m venv oncopacket-venv\nsource oncopacket-venv/bin/activate  # On Windows: oncopacket-venv\\Scripts\\activate\n</code></pre>"},{"location":"installation/#2-install-from-github-repository","title":"2: Install from GitHub repository","text":"<p>Install the latest version directly from the GitHub repository:</p> <pre><code># Ensure you are in the repo folder\ncd oncopacket\npython3 -m pip install --editable .\n</code></pre> <p>The package is installed in editable mode - any code updates are available after Python restart, without needing to reinstall.</p>"},{"location":"installation/#3-using-oncopacket-in-jupyter-notebooks-optional","title":"3. Using Oncopacket in Jupyter notebooks (optional)","text":"<p>To use Oncopacket in Jupyter notebooks, first install Jupyter and ipykernel:</p> <pre><code>python3 -m pip install jupyter ipykernel\n</code></pre> <p>Then, create a new Jupyter kernel and register it with Jupyter:</p> <pre><code>python -m ipykernel install --user --name oncopacket_env --display-name \"oncopacket\"\n</code></pre> <p>Start Jupyter to work with the notebooks in the repository:</p> <pre><code>cd notebooks\njupyter-notebook\n</code></pre> <p>At this point, a Jupyter page should open in your browser. Navigate to any notebook (and  activate the <code>oncopacket_env</code> kernel if you made one above).</p>"},{"location":"installation/#building-the-documentation","title":"Building the documentation","text":"<p>To run the mkdocs server locally for documentation development:</p> <ol> <li>Install the required packages:</li> </ol> <pre><code>pip install mkdocs-material\npip install mkdocs-material[imaging]\npip install mkdocs-material-extensions\npip install pillow cairosvg\npip install mkdocstrings[python]\n</code></pre> <ol> <li>Serve the documentation locally:</li> </ol> <pre><code>mkdocs serve\n</code></pre> <p>This will serve the documentation site at http://127.0.0.1:8000/ and dynamically show  changes. Merging to the main branch will update the public documentation site.</p>"},{"location":"workplan/","title":"Project Overview","text":"<p>Oncopacket is a Python library designed to harmonize genetic and clinical cancer data from the National Cancer Institute (NCI) into GA4GH Phenopackets, an ISO standard for representing clinical case data.</p>"},{"location":"workplan/#goals-and-objectives","title":"Goals and Objectives","text":"<p>The primary goal of Oncopacket is to facilitate the integration of cancer research data by:</p> <ol> <li>Converting data from the Cancer Research Data Commons (CRDC) to the GA4GH Phenopacket Schema</li> <li>Enabling downstream analysis using a standardized data format</li> <li>Creating a foundation for interoperability with other data sources</li> </ol>"},{"location":"workplan/#related-projects","title":"Related Projects","text":"<p>The pyphetools project has a comparable code base targeted at rare disease, while Oncopacket focuses specifically on cancer data.</p>"},{"location":"workplan/#data-sources","title":"Data Sources","text":"<p>Oncopacket currently uses:</p> <ol> <li>The Cancer Data Aggregator (CDA) API to access most cancer data elements</li> <li>Direct access to the Genomic Data Commons (GDC) API for specific elements like variant data, cancer stage, and vital status</li> </ol>"},{"location":"workplan/#project-status-and-components","title":"Project Status and Components","text":"<p>Oncopacket transforms clinical and genomic data from 12 different cancer types into standardized Phenopackets. The current implementation includes:</p> Component Description Status CdaIndividualFactory Converts subject data to Individual objects Complete CdaDiseaseFactory Converts diagnosis data to Disease objects Complete CdaBiosampleFactory Handles biological sample data Complete CdaMutationFactory Transforms mutation/variant data Complete CdaMedicalactionFactory Processes interventions and treatments Complete"},{"location":"workplan/#current-accomplishments","title":"Current Accomplishments","text":"<p>Oncopacket has been used to generate phenopackets for 23,650 individuals across 12 cancer types, with 7,816 of those having detailed mutational data. These datasets are available in a Zenodo repository.</p>"},{"location":"workplan/#future-directions","title":"Future Directions","text":"<p>Future development efforts include:</p> <ol> <li>Extending the code to incorporate more data elements from CRDC</li> <li>Adding support for additional external data sources beyond NCI</li> <li>Enhancing the mapping capabilities for oncology terms and concepts</li> <li>Developing more comprehensive analysis tools that leverage the phenopacket format</li> </ol>"},{"location":"workplan/#project-tracking","title":"Project Tracking","text":"<p>The development is tracked on the Oncopacket GitHub Project Board.</p> <p>The code repository is available at GitHub.</p>"},{"location":"cda/cda_biosample_factory/","title":"CdaBiosampleFactory","text":"<p>               Bases: <code>CdaFactory</code></p> <p>Class for creating a <code>Biosample</code> element from a row of the <code>specimen</code> CDA table.</p> <p>The class returns a GA4GH Biosample object that corresponds to a row of the speciment table. The CDA specimen table has the following fields.</p> <pre><code>- specimen_id: identifier\n- specimen_identifier: structured field with additional information\n- specimen_associated_project: e.g., CGCI-HTMCP-CC\n- days_to_collection: age in days at time specimen was collected\n- primary_disease_type: to be clarified\n- anatomical_site: body location at which specimen was collected\n- source_material_type: todo\n- specimen_type: todo\n- derived_from_specimen: todo\n- derived_from_subject: todo\n- subject_id: todo\n- researchsubject_id: todo\n</code></pre> Source code in <code>src/oncopacket/cda/cda_biosample_factory.py</code> <pre><code>class CdaBiosampleFactory(CdaFactory):\n    \"\"\"\n    Class for creating a `Biosample` element from a row of the `specimen` CDA table.\n\n    The class returns a GA4GH Biosample object that corresponds to a row of the speciment table.\n    The CDA specimen table has the following fields.\n\n        - specimen_id: identifier\n        - specimen_identifier: structured field with additional information\n        - specimen_associated_project: e.g., CGCI-HTMCP-CC\n        - days_to_collection: age in days at time specimen was collected\n        - primary_disease_type: to be clarified\n        - anatomical_site: body location at which specimen was collected\n        - source_material_type: todo\n        - specimen_type: todo\n        - derived_from_specimen: todo\n        - derived_from_subject: todo\n        - subject_id: todo\n        - researchsubject_id: todo\n    \"\"\"\n\n    def to_ga4gh(self, row) -&gt; PPKt.Biosample:\n        biosample = PPKt.Biosample()\n\n        biosample.id = row['specimen_id']\n\n        derived_from_subj = row['derived_from_subject']\n        if derived_from_subj is not None:\n            biosample.individual_id = derived_from_subj\n\n        # TODO: Biosample time_of_collection: Age at time sample was collected\n        #  -&gt; need subject age + days to collection \n        #     perform this in cda_table_importer.py under \"Retrieve GA4GH Biospecimen messages\"\n        days_to_collection = row['days_to_collection'] # number of days from index date to sample collection date\n        if days_to_collection is not None:\n            pass\n            # need PPKt.iso8601duration where PPKt.OpIndividual.id = biosample.individual_id\n            # days_to_coll_td = pd.Timedelta(days=days_to_collection)\n            # time_of_coll = PPkt.iso8601duration + days_to_coll_td\n            # biosample.time_of_collection = time_of_coll.isoformat()\n\n        # derived_from_specimen -&gt; derived_from_id \n        '''\n        Under mapping specimen it says (for GDC): \"'specimen_type' is \"'sample' or 'portion' or 'slide' \n         or 'analyte' or 'aliquot'\" and \n         'derived_from_specimen' is \"'initial specimen' if specimen_type is 'sample'; \n         otherwise Specimen.id for parent Specimen record\".\n\n         Note: may want to add a check that specimen_type from CDA is 'sample' if derived_from is 'initial specimen'\n        '''\n        derived_from = row['derived_from_specimen']    \n        if derived_from is not None:  \n            if derived_from != 'initial specimen':  \n                biosample.derived_from_id = derived_from\n\n        # anatomical_site -&gt; sampled_tissue\n        sampled_tissue = _map_anatomical_site(row['anatomical_site'])\n        if sampled_tissue is not None:\n            biosample.sampled_tissue.CopyFrom(sampled_tissue)\n\n        sample_type = _map_specimen_type(row['specimen_type'])\n        if sample_type is not None:\n            biosample.sample_type.CopyFrom(sample_type)\n\n        biosample.taxonomy.CopyFrom(HOMO_SAPIENS)\n\n        # primary_disease_type -&gt; histological_diagnosis\n        histological_diagnosis = _map_primary_disease_type(row['primary_disease_type'])\n        if histological_diagnosis is not None:\n            biosample.histological_diagnosis.CopyFrom(histological_diagnosis)\n\n        material_sample = _map_source_material_type(row['source_material_type'])\n        if material_sample is not None:\n            biosample.material_sample.CopyFrom(material_sample)\n\n        return biosample\n</code></pre>"},{"location":"cda/cda_disease_factory/","title":"CdaDiseaseFactory","text":"<p>               Bases: <code>CdaFactory</code></p> <p><code>CdaDiseaseFactory</code> uses both the <code>diagnosis</code> and <code>researchsubject</code> tables to format the information about the disease diagnosis into the Disease element of the Phenopacket Schema.</p> <p>Note, <code>CdaDiseaseFactory</code> interprets the <code>age_at_diagnosis</code> as the age of onset.</p> <ul> <li>'primary_diagnosis'</li> <li>'primary_diagnosis_site'</li> <li>'primary_diagnosis_condition'</li> <li>'stage' (For GDC entries, we have to get the stage from the GDC API, as diagnosis.tumor_stage, which CDA gets from GDC, is empty)</li> <li>'age_at_diagnosis'</li> </ul> <p>Parameters:</p> Name Type Description Default <code>disease_term_mapper</code> <code>OpMapper</code> <p>an :class:<code>OpMapper</code> for finding the disease term in the row fields. (called in mapper._configure.py)</p> required Source code in <code>src/oncopacket/cda/cda_disease_factory.py</code> <pre><code>class CdaDiseaseFactory(CdaFactory):\n    \"\"\"\n    `CdaDiseaseFactory` uses both the `diagnosis` and `researchsubject` tables to format the information\n    about the disease diagnosis into the Disease element of the Phenopacket Schema.\n\n    Note, `CdaDiseaseFactory` interprets the `age_at_diagnosis` as the age of onset.\n\n    - 'primary_diagnosis'\n    - 'primary_diagnosis_site'\n    - 'primary_diagnosis_condition'\n    - 'stage' (For GDC entries, we have to get the stage from the GDC API, as diagnosis.tumor_stage, which CDA gets from GDC, is empty)\n    - 'age_at_diagnosis'\n\n    :param disease_term_mapper: an :class:`OpMapper` for finding the disease term in the row fields.\n    (called in mapper._configure.py)\n    \"\"\"\n\n    def __init__(self, disease_term_mapper: OpMapper):\n        self._gdc_service = GdcService()\n        self._disease_term_mapper = disease_term_mapper # called with OpDiagnosisMapper.multitissue_mapper() in _configure.py\n        self._stage_mapper = OpDiseaseStageMapper()\n        self._uberon_mapper = OpUberonMapper()\n\n        self._required_fields = tuple(set(itertools.chain(\n            self._disease_term_mapper.get_fields(),\n            self._stage_mapper.get_fields(),\n            self._uberon_mapper.get_fields(),\n            ('age_at_diagnosis',),\n        )))\n        # todo -- add in ICCDO Mapper\n\n\n    def to_ga4gh(self, row: pd.Series) -&gt; pp.Disease:\n        \"\"\"\n        Convert a row of the table obtained by merging CDA `diagnosis` and `researchsubject` tables into a Disease\n         message of the Phenopacket Schema.\n\n        The row is expected to contain the following columns:\n        - 'stage'\n        - 'primary_diagnosis_condition'\n        - 'primary_diagnosis_site'\n        - 'primary_diagnosis'\n        - 'age_at_diagnosis'\n\n        :param row: a :class:`pd.Series` with a row from the merged CDA table.\n        \"\"\"\n        if not isinstance(row, pd.Series):\n            raise ValueError(f\"Invalid argument. Expected pandas Series but got {type(row)}\")\n\n        if any(field not in row for field in self._required_fields):\n            #missing = row.index.difference(self._required_fields) # this gets items in row not in _required_fields but we want the opposite\n            missing = []\n            #print(row.index)\n            for i in self._required_fields:\n                print('i:', i)\n                if i not in row.index:\n                    print('not in row.index')\n                    missing.append(i)\n\n            raise ValueError(f'Required field(s) are missing: {missing}')\n\n        # This is the component we build here.\n        disease = pp.Disease()\n\n        # map the disease term to NCIT\n        term = self._disease_term_mapper.get_ontology_term(row=row)\n        if term is None:\n            # `term` is a required field.\n            raise ValueError(f'Could not parse `term` from the row {row}')\n        disease.term.CopyFrom(term)\n\n        # We will interpret age_at_diagnosis as age of onset\n        iso8601_age_of_onset = self.days_to_iso(str(row['age_at_diagnosis']))\n        if iso8601_age_of_onset is not None:\n            disease.onset.age.iso8601duration = iso8601_age_of_onset\n\n        '''\n        Deal with stage\n         add stage if from GDC: diagnoses.tumor_stage is not filled in in GDC, so tumor_stage coming from CDA is empty\n            can use diagnoses.ajcc_pathologic_stage instead (other alternatives are diagnoses.ajcc_clinical_stage, diagnoses.ann_arbor_pathologic_stage,\n            diagnoses.ann_arbor_clinical_stage, but ajcc_pathologic_stage is the most prevalent in GDC) \n\n            Note: only selecting the stage from the 1st diagnosis out of potentially 4:\n            diagnoses.0.diagnosis_id\tdiagnoses.1.diagnosis_id\tdiagnoses.2.diagnosis_id\tdiagnoses.3.diagnosis_id\t\n        '''\n\n        #print(\"GDC stage:\", row[\"stage\"]) # empty if coming from GDC\n\n        # we are getting stage data in bulk in cda_table_importer.py now, so the below is not needed\n\n        #stage_str = ''\n        #if row[\"stage\"] == '': # probably should put in a check for data source here\n            # subj_id = re.sub(\"^[^.]+\\.\", \"\", row[\"subject_id\"]) # remove initial data source label (e.g. TCGA)\n            # gdc_stage = self._gdc_service.fetch_stage(subj_id) # returns a string\n            # stage_str = gdc_stage\n        #else:\n        #    stage_str = row[\"stage\"]\n        #print(\"stage_str: \" + stage_str)\n\n        # map to ontology:\n        stage = self._stage_mapper.get_ontology_term(stage_str=row['stage']) # returns ontology_term = PPkt.OntologyClass()\n        if stage is not None:\n            disease.disease_stage.append(stage) # list, so use append instead of CopyFrom\n        ###\n\n        # map primary site to uberon        \n        primary_site = self._uberon_mapper.get_ontology_term(row)\n        if primary_site is not None:\n            disease.primary_site.CopyFrom(primary_site)\n\n        # Deal with morphology - clinical_tnm_finding_list seems like the most\n        # appropriate place to put this\n        # TODO -- work out where this goes. I do not think the ICDO will give us TNM\n        # clinical_tnm_finding_list = None #self._parse_morphology_into_ontology_term(row)\n\n        return disease\n</code></pre>"},{"location":"cda/cda_disease_factory/#src.oncopacket.cda.CdaDiseaseFactory.to_ga4gh","title":"<code>to_ga4gh(row)</code>","text":"<p>Convert a row of the table obtained by merging CDA <code>diagnosis</code> and <code>researchsubject</code> tables into a Disease  message of the Phenopacket Schema.</p> <p>The row is expected to contain the following columns: - 'stage' - 'primary_diagnosis_condition' - 'primary_diagnosis_site' - 'primary_diagnosis' - 'age_at_diagnosis'</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Series</code> <p>a :class:<code>pd.Series</code> with a row from the merged CDA table.</p> required Source code in <code>src/oncopacket/cda/cda_disease_factory.py</code> <pre><code>def to_ga4gh(self, row: pd.Series) -&gt; pp.Disease:\n    \"\"\"\n    Convert a row of the table obtained by merging CDA `diagnosis` and `researchsubject` tables into a Disease\n     message of the Phenopacket Schema.\n\n    The row is expected to contain the following columns:\n    - 'stage'\n    - 'primary_diagnosis_condition'\n    - 'primary_diagnosis_site'\n    - 'primary_diagnosis'\n    - 'age_at_diagnosis'\n\n    :param row: a :class:`pd.Series` with a row from the merged CDA table.\n    \"\"\"\n    if not isinstance(row, pd.Series):\n        raise ValueError(f\"Invalid argument. Expected pandas Series but got {type(row)}\")\n\n    if any(field not in row for field in self._required_fields):\n        #missing = row.index.difference(self._required_fields) # this gets items in row not in _required_fields but we want the opposite\n        missing = []\n        #print(row.index)\n        for i in self._required_fields:\n            print('i:', i)\n            if i not in row.index:\n                print('not in row.index')\n                missing.append(i)\n\n        raise ValueError(f'Required field(s) are missing: {missing}')\n\n    # This is the component we build here.\n    disease = pp.Disease()\n\n    # map the disease term to NCIT\n    term = self._disease_term_mapper.get_ontology_term(row=row)\n    if term is None:\n        # `term` is a required field.\n        raise ValueError(f'Could not parse `term` from the row {row}')\n    disease.term.CopyFrom(term)\n\n    # We will interpret age_at_diagnosis as age of onset\n    iso8601_age_of_onset = self.days_to_iso(str(row['age_at_diagnosis']))\n    if iso8601_age_of_onset is not None:\n        disease.onset.age.iso8601duration = iso8601_age_of_onset\n\n    '''\n    Deal with stage\n     add stage if from GDC: diagnoses.tumor_stage is not filled in in GDC, so tumor_stage coming from CDA is empty\n        can use diagnoses.ajcc_pathologic_stage instead (other alternatives are diagnoses.ajcc_clinical_stage, diagnoses.ann_arbor_pathologic_stage,\n        diagnoses.ann_arbor_clinical_stage, but ajcc_pathologic_stage is the most prevalent in GDC) \n\n        Note: only selecting the stage from the 1st diagnosis out of potentially 4:\n        diagnoses.0.diagnosis_id\tdiagnoses.1.diagnosis_id\tdiagnoses.2.diagnosis_id\tdiagnoses.3.diagnosis_id\t\n    '''\n\n    #print(\"GDC stage:\", row[\"stage\"]) # empty if coming from GDC\n\n    # we are getting stage data in bulk in cda_table_importer.py now, so the below is not needed\n\n    #stage_str = ''\n    #if row[\"stage\"] == '': # probably should put in a check for data source here\n        # subj_id = re.sub(\"^[^.]+\\.\", \"\", row[\"subject_id\"]) # remove initial data source label (e.g. TCGA)\n        # gdc_stage = self._gdc_service.fetch_stage(subj_id) # returns a string\n        # stage_str = gdc_stage\n    #else:\n    #    stage_str = row[\"stage\"]\n    #print(\"stage_str: \" + stage_str)\n\n    # map to ontology:\n    stage = self._stage_mapper.get_ontology_term(stage_str=row['stage']) # returns ontology_term = PPkt.OntologyClass()\n    if stage is not None:\n        disease.disease_stage.append(stage) # list, so use append instead of CopyFrom\n    ###\n\n    # map primary site to uberon        \n    primary_site = self._uberon_mapper.get_ontology_term(row)\n    if primary_site is not None:\n        disease.primary_site.CopyFrom(primary_site)\n\n    # Deal with morphology - clinical_tnm_finding_list seems like the most\n    # appropriate place to put this\n    # TODO -- work out where this goes. I do not think the ICDO will give us TNM\n    # clinical_tnm_finding_list = None #self._parse_morphology_into_ontology_term(row)\n\n    return disease\n</code></pre>"},{"location":"cda/cda_factory/","title":"CdaFactory","text":"<p>The <code>CdaFactory</code> class serves as a base class for the various factory classes that transform Cancer Data Aggregator (CDA) data into components of GA4GH Phenopackets.</p>"},{"location":"cda/cda_factory/#overview","title":"Overview","text":"<p>This abstract factory class provides common functionality for its concrete subclasses: - <code>CdaIndividualFactory</code>: Transforms subject data into Individual objects - <code>CdaDiseaseFactory</code>: Transforms diagnosis data into Disease objects - <code>CdaBiosampleFactory</code>: Transforms specimen/sample data into Biosample objects - <code>CdaMutationFactory</code>: Transforms mutation data into Variant objects</p>"},{"location":"cda/cda_factory/#api-documentation","title":"API Documentation","text":"<p>Superclass for the CDA Factory Classes</p> <p>Each subclass must implement the to_ga4gh method, which transforms a row of a table from CDA to a GA4GH Message.</p> Source code in <code>src/oncopacket/cda/cda_factory.py</code> <pre><code>class CdaFactory(metaclass=abc.ABCMeta):\n    \"\"\"Superclass for the CDA Factory Classes\n\n    Each subclass must implement the to_ga4gh method, which transforms a row of a table from CDA to a GA4GH Message.\n    \"\"\"\n\n    @abc.abstractmethod\n    def to_ga4gh(self, row: pd.Series):\n        \"\"\"Return a message from the GA4GH Phenopacket Schema that corresponds to this row.\n\n        :param row: A row from the CDA\n        :type row: pd.Series\n        :returns: a message from the GA4GH Phenopacket Schema\n        :raises ValueError: if unable to parse\n        \"\"\"\n        pass\n\n    def get_item(self, row, column_name):\n        if column_name not in row:\n            raise ValueError(f\"Expecting to find {column_name} in row but did not. These are the columns: {row.columns}\")\n        return row[column_name]\n\n    def get_items_from_row(self, row, column_names):\n        if not isinstance(column_names, list):\n            raise ValueError(f\"column_names argument must be a list but was {type(column_names)}\")\n        results = []\n        for name in column_names:\n            results.append(self.get_item(row, name))\n        return results\n\n    @staticmethod\n    def days_to_iso(days: typing.Union[int, float, str]) -&gt; typing.Optional[str]:\n        \"\"\"\n        Convert the number of days of life into an ISO 8601 period representing the age of an individual.\n\n        Note, we only use the `D` designator as transformation to years or months would be lossy.\n\n        The `days` can be negative, leading to the duration of the same length.\n\n        `None` is returned if the input `str` cannot be parsed into an integer.\n\n        :param days: a `str` or `int` with a number of days of life.\n        :raises ValueError: if `days` is not an `int` or a `str`.\n        \"\"\"\n        if type(days) is int:\n            # In Python, `isinstance(True, int) == True`.\n            # However, we don't want that here.\n            pass\n        elif isinstance(days, str):\n            if simple_float_pattern.match(days):\n                days = round(float(days))\n            else:\n                return None\n        elif isinstance(days, float):\n            if math.isfinite(days):\n                days: int = round(days)\n            else:\n                return None\n        else:\n            raise ValueError(f\"days argument must be an int or a str but was {type(days)}\")\n\n        return f'P{abs(days)}D'\n\n    def get_local_share_directory(self, local_dir=None):\n        my_platform = platform.platform()\n        my_system = platform.system()\n        if local_dir is None:\n            local_dir = os.path.join(os.path.expanduser('~'), \".oncoexporter\")\n        if not os.path.exists(local_dir):\n            os.makedirs(local_dir)\n            print(f\"[INFO] Created new directory for oncoexporter at {local_dir}\")\n        return local_dir\n</code></pre>"},{"location":"cda/cda_factory/#src.oncopacket.cda.CdaFactory.days_to_iso","title":"<code>days_to_iso(days)</code>  <code>staticmethod</code>","text":"<p>Convert the number of days of life into an ISO 8601 period representing the age of an individual.</p> <p>Note, we only use the <code>D</code> designator as transformation to years or months would be lossy.</p> <p>The <code>days</code> can be negative, leading to the duration of the same length.</p> <p><code>None</code> is returned if the input <code>str</code> cannot be parsed into an integer.</p> <p>Parameters:</p> Name Type Description Default <code>days</code> <code>Union[int, float, str]</code> <p>a <code>str</code> or <code>int</code> with a number of days of life.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>days</code> is not an <code>int</code> or a <code>str</code>.</p> Source code in <code>src/oncopacket/cda/cda_factory.py</code> <pre><code>@staticmethod\ndef days_to_iso(days: typing.Union[int, float, str]) -&gt; typing.Optional[str]:\n    \"\"\"\n    Convert the number of days of life into an ISO 8601 period representing the age of an individual.\n\n    Note, we only use the `D` designator as transformation to years or months would be lossy.\n\n    The `days` can be negative, leading to the duration of the same length.\n\n    `None` is returned if the input `str` cannot be parsed into an integer.\n\n    :param days: a `str` or `int` with a number of days of life.\n    :raises ValueError: if `days` is not an `int` or a `str`.\n    \"\"\"\n    if type(days) is int:\n        # In Python, `isinstance(True, int) == True`.\n        # However, we don't want that here.\n        pass\n    elif isinstance(days, str):\n        if simple_float_pattern.match(days):\n            days = round(float(days))\n        else:\n            return None\n    elif isinstance(days, float):\n        if math.isfinite(days):\n            days: int = round(days)\n        else:\n            return None\n    else:\n        raise ValueError(f\"days argument must be an int or a str but was {type(days)}\")\n\n    return f'P{abs(days)}D'\n</code></pre>"},{"location":"cda/cda_factory/#src.oncopacket.cda.CdaFactory.to_ga4gh","title":"<code>to_ga4gh(row)</code>  <code>abstractmethod</code>","text":"<p>Return a message from the GA4GH Phenopacket Schema that corresponds to this row.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Series</code> <p>A row from the CDA</p> required <p>Returns:</p> Type Description <p>a message from the GA4GH Phenopacket Schema</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if unable to parse</p> Source code in <code>src/oncopacket/cda/cda_factory.py</code> <pre><code>@abc.abstractmethod\ndef to_ga4gh(self, row: pd.Series):\n    \"\"\"Return a message from the GA4GH Phenopacket Schema that corresponds to this row.\n\n    :param row: A row from the CDA\n    :type row: pd.Series\n    :returns: a message from the GA4GH Phenopacket Schema\n    :raises ValueError: if unable to parse\n    \"\"\"\n    pass\n</code></pre>"},{"location":"cda/cda_individual_factory/","title":"CdaIndividualFactory","text":"<p>               Bases: <code>CdaFactory</code></p> <p><code>CdaIndividualFactory</code> creates a GA4GH individual messages from a row of the CDA subject table.</p> <p>The structure of the CDA subject table is as follows:</p> <pre><code>- subject_id (*)\n- subject_identifier\n- species\n- sex (*)\n- race\n- ethnicity\n- days_to_birth (*)\n- subject_associated_project\n- vital_status (*)\n- days_to_death (*)\n- cause_of_death (*)\n</code></pre> <p>(*) indicates a used field.</p> Source code in <code>src/oncopacket/cda/cda_individual_factory.py</code> <pre><code>class CdaIndividualFactory(CdaFactory):\n    \"\"\"\n    `CdaIndividualFactory` creates a GA4GH individual messages from a row of the CDA *subject* table.\n\n    The structure of the CDA subject table is as follows:\n\n        - subject_id (*)\n        - subject_identifier\n        - species\n        - sex (*)\n        - race\n        - ethnicity\n        - days_to_birth (*)\n        - subject_associated_project\n        - vital_status (*)\n        - days_to_death (*)\n        - cause_of_death (*)\n\n    (*) indicates a used field.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._cause_of_death_mapper = OpCauseOfDeathMapper()\n        self._male_sex = {'m', 'male'}\n        self._female_sex = {'f', 'female'}\n\n    def _process_vital_status(self, row: pd.Series):\n        \"\"\"\n        :param row: a row from the CDA subject table\n        :type row: pd.Series\n        :returns: A vital status object with information about cause of death if applicable.\n        :rtype: PPkt.VitalStatus\n        \"\"\"\n        if not isinstance(row, pd.Series):\n            raise ValueError(f\"'row' argument must be pandas Series but was {type(row)}\")\n        vital_status = self.get_item(row, \"vital_status\")\n        days_to_death = self.get_item(row, \"days_to_death\")\n        if vital_status is None:\n            return None\n        valid_status = {\"Alive\", \"Dead\"}\n        if vital_status not in valid_status:\n            return None\n        vstatus = PPkt.VitalStatus()\n        if vital_status == \"Alive\":\n            vstatus.status = PPkt.VitalStatus.ALIVE\n        elif vital_status == \"Dead\":\n            vstatus.status = PPkt.VitalStatus.DECEASED\n        if days_to_death is not None:\n            try:\n                dtd = int(days_to_death)\n                vstatus.survival_time_in_days = dtd\n            except:\n                # TODO: report?\n                pass\n        cause = self._cause_of_death_mapper.get_ontology_term(row)\n        if cause is not None:\n            vstatus.cause_of_death.CopyFrom(cause)\n        return vstatus\n\n    def to_ga4gh(self, row:pd.Series):\n        \"\"\"\n        convert a row from the CDA subject table into an Individual message (GA4GH Phenopacket Schema)\n\n        :param row: a row from the CDA subject table\n        :type row: pd.Series\n        :returns: A GA4GH Phenopacket Schema Individual object that corresponds to the subject in this row.\n        :rtype: PPkt.Individual\n        :raises ValueError: if the input is unparsable.\n        \"\"\"\n        if not isinstance(row, pd.Series):\n            raise ValueError(f\"Invalid argument. Expected pandas series but got {type(row)}\")\n        row = row.astype(str)\n        subject_id = row['subject_id']\n        # subject_identifier = row['subject_identifier']\n        # species = row['species']\n        sex = row['sex']\n        # race = row['race']\n        # ethnicity = row['ethnicity']\n        days_to_birth = row['days_to_birth']\n        # a valid date looks like this: '-15987.0'\n        if days_to_birth.startswith(\"-\"):\n            days_to_birth = days_to_birth[1:]\n        iso_age = None\n        vstat = None\n        try:\n            # we need to parse '15987.0' first as a float and then transform to int\n            d_to_b = int(float(days_to_birth))\n            iso_age = self.days_to_iso(days=d_to_b)\n            vstat = self._process_vital_status(row)\n        except Exception:\n            # TODO: handle in a better way\n            pass\n        # subject_associated_project = row['subject_associated_project']\n\n\n        individual = PPkt.Individual()\n        individual.id = subject_id\n\n        # time_at_last_encounter\n        if iso_age is not None:\n            individual.time_at_last_encounter.age.iso8601duration = iso_age\n\n        # vital status\n        if vstat is not None:\n            individual.vital_status.CopyFrom(vstat)\n\n        # sex\n        if sex in self._male_sex:\n            individual.sex = PPkt.MALE\n        elif sex in self._female_sex:\n            individual.sex = PPkt.FEMALE\n        else:\n            individual.sex = PPkt.UNKNOWN_SEX\n\n        # taxonomy, always Homo here\n        individual.taxonomy.id = \"NCBITaxon:9606\"\n        individual.taxonomy.label = \"Homo sapiens\"\n\n        return individual\n</code></pre>"},{"location":"cda/cda_individual_factory/#src.oncopacket.cda.CdaIndividualFactory.to_ga4gh","title":"<code>to_ga4gh(row)</code>","text":"<p>convert a row from the CDA subject table into an Individual message (GA4GH Phenopacket Schema)</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Series</code> <p>a row from the CDA subject table</p> required <p>Returns:</p> Type Description <code>PPkt.Individual</code> <p>A GA4GH Phenopacket Schema Individual object that corresponds to the subject in this row.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the input is unparsable.</p> Source code in <code>src/oncopacket/cda/cda_individual_factory.py</code> <pre><code>def to_ga4gh(self, row:pd.Series):\n    \"\"\"\n    convert a row from the CDA subject table into an Individual message (GA4GH Phenopacket Schema)\n\n    :param row: a row from the CDA subject table\n    :type row: pd.Series\n    :returns: A GA4GH Phenopacket Schema Individual object that corresponds to the subject in this row.\n    :rtype: PPkt.Individual\n    :raises ValueError: if the input is unparsable.\n    \"\"\"\n    if not isinstance(row, pd.Series):\n        raise ValueError(f\"Invalid argument. Expected pandas series but got {type(row)}\")\n    row = row.astype(str)\n    subject_id = row['subject_id']\n    # subject_identifier = row['subject_identifier']\n    # species = row['species']\n    sex = row['sex']\n    # race = row['race']\n    # ethnicity = row['ethnicity']\n    days_to_birth = row['days_to_birth']\n    # a valid date looks like this: '-15987.0'\n    if days_to_birth.startswith(\"-\"):\n        days_to_birth = days_to_birth[1:]\n    iso_age = None\n    vstat = None\n    try:\n        # we need to parse '15987.0' first as a float and then transform to int\n        d_to_b = int(float(days_to_birth))\n        iso_age = self.days_to_iso(days=d_to_b)\n        vstat = self._process_vital_status(row)\n    except Exception:\n        # TODO: handle in a better way\n        pass\n    # subject_associated_project = row['subject_associated_project']\n\n\n    individual = PPkt.Individual()\n    individual.id = subject_id\n\n    # time_at_last_encounter\n    if iso_age is not None:\n        individual.time_at_last_encounter.age.iso8601duration = iso_age\n\n    # vital status\n    if vstat is not None:\n        individual.vital_status.CopyFrom(vstat)\n\n    # sex\n    if sex in self._male_sex:\n        individual.sex = PPkt.MALE\n    elif sex in self._female_sex:\n        individual.sex = PPkt.FEMALE\n    else:\n        individual.sex = PPkt.UNKNOWN_SEX\n\n    # taxonomy, always Homo here\n    individual.taxonomy.id = \"NCBITaxon:9606\"\n    individual.taxonomy.label = \"Homo sapiens\"\n\n    return individual\n</code></pre>"},{"location":"cda/cda_mutation_factory/","title":"CdaMutationFactory","text":"<p>               Bases: <code>CdaFactory</code></p> <p><code>CdaMutationFactory</code> maps a row of the CDA mutation table into <code>VariantInterpretation</code> element of the Phenopacket Schema.</p> <p>See <code>here &lt;https://cda.readthedocs.io/en/latest/Schema/fields_mutation/&gt;</code>_ for the mutation table schema.</p> <p>Initial fields to map to phenopackets: - cda_subject_id - Entrez_Gene_Id - Hugo_Symbol - NCBI_Build - Chromosome - Start_Position - End_Position - Reference_Allele - Tumor_Seq_Allele2 - dbSNP_RS - Transcript_ID - HGVSc - ENSP - HGVSp_Short - Mutation_Status - t_depth - t_ref_count - t_alt_count - n_depth - n_ref_count - n_alt_count</p> <p>Additional fields to map, not required for pilot: - primary_site - dbSNP_Val_Status - HGVSp - Match_Norm_Seq_Allele1 - Match_Norm_Seq_Allele2 - Tumor_Validation_Allele1 - Tumor_Validation_Allele2 - Match_Norm_Validation_Allele1 - Match_Norm_Validation_Allele2</p> Source code in <code>src/oncopacket/cda/cda_mutation_factory.py</code> <pre><code>class CdaMutationFactory(CdaFactory):\n    \"\"\"\n    `CdaMutationFactory` maps a row of the CDA mutation table into `VariantInterpretation`\n    element of the Phenopacket Schema.\n\n    See `here &lt;https://cda.readthedocs.io/en/latest/Schema/fields_mutation/&gt;`_ for\n    the mutation table schema.\n\n    Initial fields to map to phenopackets:\n    - cda_subject_id\n    - Entrez_Gene_Id\n    - Hugo_Symbol\n    - NCBI_Build\n    - Chromosome\n    - Start_Position\n    - End_Position\n    - Reference_Allele\n    - Tumor_Seq_Allele2\n    - dbSNP_RS\n    - Transcript_ID\n    - HGVSc\n    - ENSP\n    - HGVSp_Short\n    - Mutation_Status\n    - t_depth\n    - t_ref_count\n    - t_alt_count\n    - n_depth\n    - n_ref_count\n    - n_alt_count\n\n    Additional fields to map, not required for pilot:\n    - primary_site\n    - dbSNP_Val_Status\n    - HGVSp\n    - Match_Norm_Seq_Allele1\n    - Match_Norm_Seq_Allele2\n    - Tumor_Validation_Allele1\n    - Tumor_Validation_Allele2\n    - Match_Norm_Validation_Allele1\n    - Match_Norm_Validation_Allele2\n    \"\"\"\n\n    def __init__(self):\n        self._column_names = [\n            'Entrez_Gene_Id', 'Hugo_Symbol',\n            'NCBI_Build', 'Chromosome', 'Start_Position', 'End_Position', 'Reference_Allele', 'Tumor_Seq_Allele2',\n            'dbSNP_RS',\n            'Transcript_ID', 'HGVSc', 'ENSP', 'HGVSp_Short',\n            'Mutation_Status',\n            't_depth', 't_ref_count', 't_alt_count',\n            'n_depth', 'n_ref_count', 'n_alt_count',\n        ]\n        self._logger = logging.getLogger(__name__)\n\n    def to_ga4gh(self, row: pd.Series) -&gt; pp.VariantInterpretation:\n        \"\"\"\n        Convert a row from the CDA mutation table\n        into a VariantInterpretation message (GA4GH Phenopacket Schema).\n\n        :param row: a :class:`pd.Series` with the row of the CDA mutation table.\n        \"\"\"\n        if not isinstance(row, pd.Series):\n            raise ValueError(f\"Invalid argument. Expected pandas series but got {type(row)}\")\n\n        if any(field not in row for field in self._column_names):\n            keys = set(row.index)\n            missing = keys.difference(self._column_names)\n            raise ValueError(f'Missing field(s): {missing}')\n\n\n        vdescriptor = pp.VariationDescriptor()\n\n        vdescriptor.id = self._generate_id(row)\n\n        # Gene context\n        if row['Hugo_Symbol'] is not None and row['Entrez_Gene_Id'] is not None:\n            vdescriptor.gene_context.value_id = f\"NCBIGene:{row['Entrez_Gene_Id']}\"\n            vdescriptor.gene_context.symbol = row['Hugo_Symbol']\n\n        # We may consider including an HGVS c expression for ALL transcripts,\n        # using the `all_effects` field that looks like this:\n        # SPRY3,missense_variant,p.G118A,ENST00000302805,NM_005840.2,c.353G&gt;C,MODERATE,YES,deleterious(0),benign(0.001),1;SPRY3,missense_variant,p.G118A,ENST00000675360,NM_001304990.1,c.353G&gt;C,MODERATE,,deleterious(0),benign(0.001),1\n        if row['Transcript_ID'] is not None and row['HGVSc'] is not None:\n            hgvs_expression = pp.Expression()\n            hgvs_expression.syntax = \"hgvs.c\"\n            hgvs_expression.value = f\"{row['Transcript_ID']}:{row['HGVSc']}\"\n            vdescriptor.expressions.append(hgvs_expression)\n\n        if row['ENSP'] is not None and row['HGVSp_Short'] is not None:\n            hgvs_expression = pp.Expression()\n            hgvs_expression.syntax = \"hgvs.p\"\n            hgvs_expression.value = f\"{row['ENSP']}:{row['HGVSp_Short']}\"\n            vdescriptor.expressions.append(hgvs_expression)\n\n        # TODO: consider adding HGVS.g\n\n        vcf_record = self._create_vcf_record(row)\n        if vcf_record is not None:\n            vdescriptor.vcf_record.CopyFrom(vcf_record)\n\n        # Tumor/normal depths\n        for name in ('t_depth', 't_ref_count', 't_alt_count',\n                     'n_depth', 'n_ref_count', 'n_alt_count'):\n            val = row[name]\n            ext = pp.Extension()\n            ext.name = name\n            # We expect an `int` or `None`.\n            ext.value = str(val)\n            vdescriptor.extensions.append(ext)\n\n        # Mutation status\n        ms = row['Mutation_Status']\n        if ms is not None and len(ms) &gt; 1:\n            ext = pp.Extension()\n            ext.name = 'Mutation_Status'\n            ext.value = ms\n            vdescriptor.extensions.append(ext)\n\n        vdescriptor.molecule_context = pp.MoleculeContext.genomic\n\n        vinterpretation = pp.VariantInterpretation()\n        vinterpretation.variation_descriptor.CopyFrom(vdescriptor)\n        return vinterpretation\n\n    def _create_vcf_record(self, row: pd.Series) -&gt; typing.Optional[pp.VcfRecord]:\n        ref = row['Reference_Allele']\n        alt = row['Tumor_Seq_Allele2']\n        if ref == '-' or alt == '-':\n            self._logger.debug(\n                'Cannot create a VCF record due to missing bases in the Reference_Allele/Tumor_Seq_Allele2 alleles: %s',\n                row)\n            return None\n\n        vcf_record = pp.VcfRecord()\n        vcf_record.genome_assembly = row['NCBI_Build']\n        vcf_record.chrom = row['Chromosome']\n        rs_id = row['dbSNP_RS']\n        if rs_id is not None:\n            vcf_record.id = rs_id\n        vcf_record.pos = row['Start_Position']\n        vcf_record.ref = ref\n        vcf_record.alt = alt\n        return vcf_record\n\n    @staticmethod\n    def _generate_id(row: pd.Series) -&gt; str:\n        return str(hash(''.join(str(x) for x in row.values)))\n</code></pre>"},{"location":"cda/cda_mutation_factory/#src.oncopacket.cda.CdaMutationFactory.to_ga4gh","title":"<code>to_ga4gh(row)</code>","text":"<p>Convert a row from the CDA mutation table into a VariantInterpretation message (GA4GH Phenopacket Schema).</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Series</code> <p>a :class:<code>pd.Series</code> with the row of the CDA mutation table.</p> required Source code in <code>src/oncopacket/cda/cda_mutation_factory.py</code> <pre><code>def to_ga4gh(self, row: pd.Series) -&gt; pp.VariantInterpretation:\n    \"\"\"\n    Convert a row from the CDA mutation table\n    into a VariantInterpretation message (GA4GH Phenopacket Schema).\n\n    :param row: a :class:`pd.Series` with the row of the CDA mutation table.\n    \"\"\"\n    if not isinstance(row, pd.Series):\n        raise ValueError(f\"Invalid argument. Expected pandas series but got {type(row)}\")\n\n    if any(field not in row for field in self._column_names):\n        keys = set(row.index)\n        missing = keys.difference(self._column_names)\n        raise ValueError(f'Missing field(s): {missing}')\n\n\n    vdescriptor = pp.VariationDescriptor()\n\n    vdescriptor.id = self._generate_id(row)\n\n    # Gene context\n    if row['Hugo_Symbol'] is not None and row['Entrez_Gene_Id'] is not None:\n        vdescriptor.gene_context.value_id = f\"NCBIGene:{row['Entrez_Gene_Id']}\"\n        vdescriptor.gene_context.symbol = row['Hugo_Symbol']\n\n    # We may consider including an HGVS c expression for ALL transcripts,\n    # using the `all_effects` field that looks like this:\n    # SPRY3,missense_variant,p.G118A,ENST00000302805,NM_005840.2,c.353G&gt;C,MODERATE,YES,deleterious(0),benign(0.001),1;SPRY3,missense_variant,p.G118A,ENST00000675360,NM_001304990.1,c.353G&gt;C,MODERATE,,deleterious(0),benign(0.001),1\n    if row['Transcript_ID'] is not None and row['HGVSc'] is not None:\n        hgvs_expression = pp.Expression()\n        hgvs_expression.syntax = \"hgvs.c\"\n        hgvs_expression.value = f\"{row['Transcript_ID']}:{row['HGVSc']}\"\n        vdescriptor.expressions.append(hgvs_expression)\n\n    if row['ENSP'] is not None and row['HGVSp_Short'] is not None:\n        hgvs_expression = pp.Expression()\n        hgvs_expression.syntax = \"hgvs.p\"\n        hgvs_expression.value = f\"{row['ENSP']}:{row['HGVSp_Short']}\"\n        vdescriptor.expressions.append(hgvs_expression)\n\n    # TODO: consider adding HGVS.g\n\n    vcf_record = self._create_vcf_record(row)\n    if vcf_record is not None:\n        vdescriptor.vcf_record.CopyFrom(vcf_record)\n\n    # Tumor/normal depths\n    for name in ('t_depth', 't_ref_count', 't_alt_count',\n                 'n_depth', 'n_ref_count', 'n_alt_count'):\n        val = row[name]\n        ext = pp.Extension()\n        ext.name = name\n        # We expect an `int` or `None`.\n        ext.value = str(val)\n        vdescriptor.extensions.append(ext)\n\n    # Mutation status\n    ms = row['Mutation_Status']\n    if ms is not None and len(ms) &gt; 1:\n        ext = pp.Extension()\n        ext.name = 'Mutation_Status'\n        ext.value = ms\n        vdescriptor.extensions.append(ext)\n\n    vdescriptor.molecule_context = pp.MoleculeContext.genomic\n\n    vinterpretation = pp.VariantInterpretation()\n    vinterpretation.variation_descriptor.CopyFrom(vdescriptor)\n    return vinterpretation\n</code></pre>"},{"location":"cda/cda_table_importer/","title":"CdaTableImporter","text":"<p>               Bases: <code>CdaImporter[fetch_rows]</code></p> <p>This class is the entry point for transforming CDA data into GA4GH Phenopackets. Client code only needs to initialize it with a CDA query, and it can return phenopackets with the :func:<code>get_ga4gh_phenopackets</code>. It also returns individual tables for that can be used for testing or visualizing data.</p> <p>The CDA query determines the cohort that will be retrieved from CDA. This class then retrieves data for this cohort in form of pandas DataFrames and extracts data for phenopacket construction using the data in the tables</p> <p>Parameters:</p> Name Type Description Default <code>disease_factory</code> <code>CdaDiseaseFactory</code> <p>the component for mapping CDA table into Disease element of the Phenopacket Schema.</p> required <code>cache_dir</code> <code>Optional[str]</code> <p>a <code>str</code> with path to the folder to store the cache files</p> <code>None</code> <code>use_cache</code> <code>bool</code> <p>if True, cache/retrieve from cache</p> <code>False</code> <code>page_size</code> <p>Number of pages to retrieve at once. Defaults to <code>10000</code>  New CDA: https://cda.readthedocs.io/en/latest/documentation/cdapython/code_update/#returning-a-matrix-of-results old: all of the functions previously used with, or chained onto Q()...run() have been replaced with the single function fetch_rows() new: `fetch_rows(table=, )  https://cda.readthedocs.io/en/latest/documentation/cdapython/code_update/#parameters old: page_size, limit, and count parameters have been removed new: column_values always returns all unique values and their counts by default, however there are several new parameters  old: system= new: data_source= can now take a list, as in data_source=[\"GDC\", \"PDC\"]  new: sort_by= sort results by any column  new: force= For columns with an extremely large number of unique values, such as filename, the query will fail with a large data warning. You can override the warning with Force=True  tables: ['diagnosis', 'file', 'researchsubject', 'somatic_mutation', 'specimen', 'subject', 'treatment'] required Source code in <code>src/oncopacket/cda/cda_table_importer.py</code> <pre><code>class CdaTableImporter(CdaImporter[fetch_rows]):\n    \"\"\"This class is the entry point for transforming CDA data into GA4GH Phenopackets. Client code only needs\n    to initialize it with a CDA query, and it can return phenopackets with the :func:`get_ga4gh_phenopackets`.\n    It also returns individual tables for that can be used for testing or visualizing data.\n\n    The CDA query determines the cohort that will be retrieved from CDA. This class then retrieves data\n    for this cohort in form of pandas DataFrames and extracts data for phenopacket construction using the data\n    in the tables\n\n    :param disease_factory: the component for mapping CDA table into Disease element of the Phenopacket Schema.\n    :param cache_dir: a `str` with path to the folder to store the cache files\n    :param use_cache: if True, cache/retrieve from cache\n    :param page_size: Number of pages to retrieve at once. Defaults to `10000`\n\n    New CDA:\n    https://cda.readthedocs.io/en/latest/documentation/cdapython/code_update/#returning-a-matrix-of-results\n    old: all of the functions previously used with, or chained onto Q()...run() have been replaced with the single function fetch_rows()\n    new: `fetch_rows(table=, )\n\n    https://cda.readthedocs.io/en/latest/documentation/cdapython/code_update/#parameters\n    old: page_size, limit, and count parameters have been removed\n    new: column_values always returns all unique values and their counts by default, however there are several new parameters\n\n    old: system=&lt;data source&gt;\n    new: data_source=&lt;data source&gt; can now take a list, as in data_source=[\"GDC\", \"PDC\"]\n\n    new: sort_by=&lt;column:asc/desc&gt; sort results by any column\n\n    new: force=&lt;True/False&gt; For columns with an extremely large number of unique values, such as filename, the query will fail with a large data warning.\n    You can override the warning with Force=True\n\n    tables: ['diagnosis', 'file', 'researchsubject', 'somatic_mutation', 'specimen', 'subject', 'treatment']\n    \"\"\"\n\n    def __init__(self,\n                 disease_factory: CdaDiseaseFactory,\n                 use_cache: bool = False,\n                 cache_dir: typing.Optional[str] = None,\n                 #page_size: int = 10000,\n                 gdc_timeout: int = 100000,\n                 ):\n        self._use_cache = use_cache\n        #self._page_size = page_size # not in new CDA\n\n        self._individual_factory = CdaIndividualFactory()\n        self._disease_factory = disease_factory \n        self._specimen_factory = CdaBiosampleFactory()\n        self._mutation_factory = CdaMutationFactory()\n        self._gdc_service = GdcService(timeout=gdc_timeout)\n\n        if cache_dir is None:\n            self._cache_dir = os.path.join(os.getcwd(), '.oncoexporter_cache')\n            if not os.path.isdir(self._cache_dir):\n                os.makedirs(self._cache_dir, exist_ok=True)\n        else:\n            if not os.path.isdir(cache_dir) or not os.access(cache_dir, os.W_OK):\n                raise ValueError(f'`cache_dir` must be a writable directory: {cache_dir}')\n\n    def _get_cda_df(self, callback_fxn, cache_name: str):\n        fpath_cache = os.path.join(self._cache_dir, cache_name)\n        if self._use_cache and os.path.isfile(fpath_cache):\n            print(f\"\\tRetrieving dataframe {fpath_cache}\")\n            with open(fpath_cache, 'rb') as cachehandle:\n                print(f\"loading cached dataframe from {fpath_cache}\")\n                individual_df = pickle.load(cachehandle)\n        else:\n            print(f\"\\tcalling CDA function\")\n            individual_df = callback_fxn()\n            if self._use_cache:\n                print(f\"Creating cached dataframe as {fpath_cache}\")\n                with open(fpath_cache, 'wb') as f:\n                    pickle.dump(individual_df, f)\n        return individual_df\n\n    def get_subject_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n        \"\"\"\n        Retrieve the subject dataframe from CDA\n\n        This method uses the Query that was passed to the constructor to retrieve data from the CDA subject table\n\n        Note: 1/31/25.  The new version of CDA is returning all records that have a subject that is in GDC (essentially all of them), \n        so despite the data_source='GDC', we get back rows from other data commons.    \n\n        :raises: ValueError if no rows are returned\n        :returns: pandas DataFrame that corresponds to the CDA subject table.\n        :rtype: pd.DataFrame\n        \"\"\"\n        print(\"\\nGetting subject df...\")\n\n        # Define the callable to fetch the subject rows\n        callable = lambda: fetch_rows(table='subject', **q, provenance=True)\n\n        # Get the subject DataFrame (or load from cache if available)\n        subject_df = self._get_cda_df(callable, f\"{cohort_name}_individual_df.pkl\")\n\n        # Check if the returned DataFrame is empty\n        if subject_df is None or subject_df.empty:\n            message = f\"No subject rows returned for cohort '{cohort_name}'. \" \\\n                      f\"Please check your query parameters or data source.\"\n            print(f\"Error: {message}\")\n            # Fail gracefully by raising an exception with a descriptive message.\n            raise ValueError(message)\n\n        # Process the DataFrame further only if it has data\n        subject_df = subject_df.drop(columns=['subject_data_source_id'], axis=1)\n        subject_df = subject_df.drop_duplicates()\n\n        # filter here for data source (TODO: deal with multiple sources)\n        if 'data_source' in q.keys():\n            subject_df = subject_df[subject_df['subject_data_source'] == q['data_source']]\n        #print(\"subject_df filtered dim: \", subject_df.shape)\n        #subject_df.to_csv('subject_df.txt', sep='\\t')\n        print(\"obtained subject_df\")\n\n        return subject_df\n\n    def get_researchsubject_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n\n        print(\"\\nGetting researchsubject df...\")\n        # tried link_to_table='diagnosis' but it doesn't add any columns\n        # research = fetch_rows(table='researchsubject', provenance=True)\n        rsub_callable = lambda: fetch_rows( table='researchsubject', **q , add_columns=['subject_id'])\n        rsub_df = self._get_cda_df(rsub_callable, f\"{cohort_name}_researchsubject_df.pkl\")\n        print(\"obtained researchsubject_df\")\n        #rsub_df.to_csv('rsub_df.txt', sep='\\t')\n\n        return rsub_df\n\n    def get_diagnosis_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n\n        print(\"\\nGetting diagnosis df...\")\n        # diag = fetch_rows(table='diagnosis', add_columns=['researchsubject_id'])\n        diagnosis_callable = lambda: fetch_rows( table='diagnosis', **q , add_columns=['subject_id'])\n        diagnosis_df = self._get_cda_df(diagnosis_callable, f\"{cohort_name}_diagnosis_df.pkl\")\n        print(\"obtained diagnosis_df\")\n        #diagnosis_df.to_csv('diagnosis_df.txt', sep='\\t')\n\n        return diagnosis_df\n\n    def get_specimen_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n        \"\"\"Retrieve the subject dataframe from CDA\n\n        This method uses the Query that was passed to the constructor to retrieve data from the CDA subject table\n\n        :raises: raises an exception if the query object was not properly initialized\n        :returns: pandas DataFrame that corresponds to the CDA subject table.\n        :rtype: pd.DataFrame\n        \"\"\"\n        print(\"\\nGetting specimen df...\")\n        #specimen_callable = lambda: q.specimen.run(page_size=self._page_size).get_all().to_dataframe()\n        specimen_callable = lambda: fetch_rows( table='specimen', **q, add_columns=['subject_id'] )\n        specimen_df = self._get_cda_df(specimen_callable, f\"{cohort_name}_specimen_df.pkl\")\n        #specimen_df.to_csv('specimen_df.txt', sep='\\t')\n        return specimen_df\n\n    def get_treatment_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n        print(\"\\nGetting treatment df...\")\n        #treatment_callable = lambda: q.treatment.run(page_size=self._page_size).get_all().to_dataframe()\n        treatment_callable = lambda: fetch_rows( table='treatment', **q, add_columns=['subject_id'] )\n        treatment_df = self._get_cda_df(treatment_callable, f\"{cohort_name}_treatment_df.pkl\")\n        #treatment_df.to_csv('treatment_df.txt', sep='\\t')\n        return treatment_df\n\n    def get_ga4gh_phenopackets(self, source: dict, **kwargs) -&gt; typing.List[PPkt.Phenopacket]:\n        \"\"\"Get a list of GA4GH phenopackets corresponding to the individuals returned by the query passed to the constructor.\n\n        :returns: A list of GA4GH phenopackets corresponding to the individuals selected by the query passed to the constructor.\n        :rtype: typing.List[PPkt.Phenopacket]\n\n        New version of CDA: need to change Q to fetch_rows()\n        \"\"\"\n\n        if 'cohort_name' in kwargs:\n            cohort_name = kwargs['cohort_name']\n        else:\n            # Format timestamp as a string, for example: 'YYYY-MM-DD HH:MM:SS'\n            ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n            cohort_name = f'cohort-{ts}'\n\n        # Dictionary of phenopackets, keys are the phenopacket ids.\n        ppackt_d = {}\n\n        # First obtain the pandas DataFrames from the CDA tables with rows that correspond to the Query\n        # (MLS 6/18/24) rewriting this to get subject, researchsubject, diagnosis, specimen, and treatment dataframes,\n        # then merge them here to avoid getting researchsubject and subject dataframes multiple times.\n\n        subject_df = self.get_subject_df(source, cohort_name)\n        rsub_df = self.get_researchsubject_df(source, cohort_name)\n        diagnosis_df = self.get_diagnosis_df(source, cohort_name)\n        specimen_df = self.get_specimen_df(source, cohort_name)\n        treatment_df = self.get_treatment_df(source, cohort_name)\n\n        # merge dfs:\n        # can actually just make one merged df with subject_id, researchsubject_id, primary_diagnosis_condition,\n        # primary_diagnosis_site, primary_diagnosis, age_at_diagnosis, stage\n        # loop through it to generate:\n        #  - disease_factory\n        #  - vital_status\n        #  - variants\n        sub_rsub_diag_df = subject_df.merge(rsub_df, on='subject_id', how='outer')\n        sub_rsub_diag_df = sub_rsub_diag_df.merge(diagnosis_df, on='subject_id', how='outer')\n\n        #sub_rsub_diag_df.to_csv(\"sub_rsub_diag_df.txt\", sep='\\t') \n        print(\"merged subject-researchsubject-diagnosis df\")\n        '''\n        Have a problem with patients that have multiple researchsubject IDs with differing primary diagnosis sites\n\n        \tsubject_id\tcause_of_death\tdays_to_birth\tdays_to_death\tethnicity\trace\tsex\tspecies\tvital_status\tresearchsubject_id\tprimary_diagnosis_site\n        0\tTCGA.TCGA-AG-3881\t\t-30467\t&lt;NA&gt;\t\t\tfemale\thuman\tAlive\tphs003155.TCGA-AG-3881\t\n        1\tTCGA.TCGA-AG-3881\t\t-30467\t&lt;NA&gt;\t\t\tfemale\thuman\tAlive\tTCGA-READ.TCGA-AG-3881\t\n        2\tTCGA.TCGA-AG-3881\t\t-30467\t&lt;NA&gt;\t\t\tfemale\thuman\tAlive\ttcga_read.TCGA-AG-3881.RS\trectum\n        '''\n\n        # Now use the CdaFactory classes to transform the information from the DataFrames into\n        # components of the GA4GH Phenopacket Schema\n        # Add these components one at a time to Phenopacket objects.\n\n        print(\"\\nConverting to Phenopackets...\\n\")\n\n        '''\n        required fields:\n        - 'stage'                           # getting from GDC \n        - 'primary_diagnosis_condition'     # diagnosis mapper \n        - 'primary_diagnosis_site'          # uberon mapper\n        - 'primary_diagnosis'               # diagnosis mapper\n        - 'age_at_diagnosis'                # disease term mapper\n        '''\n\n        # Retrieve GA4GH Individual messages\n        for _, row in tqdm(subject_df.iterrows(), total=len(subject_df), desc= \"individual dataframe\"):\n            try:\n                individual_message = self._individual_factory.to_ga4gh(row=row)\n            except ValueError as e:\n                # TODO: decide how to handle depending on your paranoia\n                #\n                pass\n\n            individual_id = individual_message.id\n            ppackt = PPkt.Phenopacket()\n            ppackt.id = f'{cohort_name}-{individual_id}'\n            ppackt.subject.CopyFrom(individual_message)\n            ppackt_d[individual_id] = ppackt\n\n        # get stage dictionary, map to subject ID\n        print(\"Retrieving stage info from GDC...\", end='')\n        stage_dict = self._gdc_service.fetch_stage_dict()\n        print(\"Done!\")\n\n        # remove initial data source label: TCGA.TCGA-4J-AA1J &gt; TCGA-4J-AA1J\n        sub_rsub_diag_df['subject_id_short'] = sub_rsub_diag_df[\"subject_id\"].str.extract(r'^[^\\.]+\\.(.+)', expand=False)\n        sub_rsub_diag_df['stage'] = sub_rsub_diag_df['subject_id_short'].map(stage_dict).fillna(sub_rsub_diag_df['stage'])\n\n        sub_rsub_diag_df['primary_diagnosis'] = sub_rsub_diag_df['primary_diagnosis'].fillna('') # remove nans (not sure why they are there)\n        sub_rsub_diag_df.to_csv('sub_rsub_diag_df.txt', sep='\\t')\n\n\n\n        # Retrieve GA4GH Disease messages\n        for _, row in tqdm(sub_rsub_diag_df.iterrows(), total=len(sub_rsub_diag_df.index), desc=\"creating disease messsages\"):\n\n\n            disease_message = self._disease_factory.to_ga4gh(row)\n            pp = ppackt_d.get(row[\"subject_id\"])\n\n            # Do not add the disease if it is already in the phenopacket.\n            if not any(disease.term.id == disease_message.term.id for disease in pp.diseases):\n                pp.diseases.append(disease_message)\n\n            # need to check if we have the age_at_diagnosis in the phenopacket message\n            for disease in pp.diseases:\n                if not disease.HasField(\"onset\") and disease.term.id == disease_message.term.id and disease_message.HasField(\"onset\"):\n                    disease.onset.CopyFrom(disease_message.onset)\n\n            # get vital status from GDC - probably not needed (should be same as subject_df obtained from CDA)\n            # vital_status = self._gdc_service.fetch_vital_status(subj_id)\n            # ppackt_d.get(individual_id).subject.vital_status.CopyFrom(vital_status)\n\n        # Get variant data \n        # -&gt;takes ~15-45 minutes due to API calls to GDC\n        # should sub_rsub_diag_df already be filtered to GDC?\n        sub_rsub_diag_GDC_df = sub_rsub_diag_df[sub_rsub_diag_df['subject_data_source'] == 'GDC']\n\n        for _, row in tqdm(sub_rsub_diag_GDC_df.iterrows(), total=len(sub_rsub_diag_df.index), desc=\"getting variants from GDC\"):\n\n            individual_id = row[\"subject_id\"]\n            # have to strip off the leading name before first period\n            # e.g. TCGA.TCGA-05-4250 -&gt; TCGA-05-4250\n            subj_id = re.sub(\"^[^.]+\\.\", \"\", individual_id)\n\n            # get variants\n            variant_interpretations = self._gdc_service.fetch_variants(subj_id) \n            if len(variant_interpretations) == 0:\n                #print(\"No variants found\")\n                continue\n            #else:\n                #print(\"length variant_interpretations: {}\".format(len(variant_interpretations)))\n\n            # TODO: improve/enhance diagnosis term annotations\n            diagnosis = PPkt.Diagnosis()\n            diagnosis.disease.id = \"NCIT:C3262\"\n            diagnosis.disease.label = \"Neoplasm\"\n\n            for variant in variant_interpretations:\n                genomic_interpretation = PPkt.GenomicInterpretation()\n                genomic_interpretation.subject_or_biosample_id = individual_id\n                genomic_interpretation.interpretation_status = PPkt.GenomicInterpretation.InterpretationStatus.UNKNOWN_STATUS\n                genomic_interpretation.variant_interpretation.CopyFrom(variant)\n\n                diagnosis.genomic_interpretations.append(genomic_interpretation)\n\n            interpretation = PPkt.Interpretation()\n            interpretation.id = f\"{individual_id}-{row['researchsubject_id']}\"\n            interpretation.progress_status = PPkt.Interpretation.ProgressStatus.IN_PROGRESS\n            interpretation.diagnosis.CopyFrom(diagnosis)\n\n            ppackt_d.get(individual_id).interpretations.append(interpretation)\n\n\n        # Retrieve GA4GH Biospecimen messages\n        for idx, row in tqdm(specimen_df.iterrows(),total=len(specimen_df.index), desc=\"specimen/biosample dataframe\"):\n            biosample_message = self._specimen_factory.to_ga4gh(row)\n            individual_id = row[\"subject_id\"]\n            if individual_id not in ppackt_d:\n                raise ValueError(f\"Attempt to enter unknown individual ID from biosample factory: \\\"{individual_id}\\\"\")\n\n            # convert CDA days_to_collection to PPKt time_of_collection\n            #         days_to_collection: number of days from index date to sample collection date\n            #         time_of_collection: Age of subject at time sample was collected\n            if not pd.isna(row['days_to_collection']):\n                days_to_coll_iso = CdaFactory.days_to_iso(int(row[\"days_to_collection\"]))\n\n            # TODO: fix the code below!\n            # this should work if both are pd.Timedelta:\n            # time_of_collection = ppackt_d[individual_id][\"iso8601duration\"] + days_to_coll_iso # should it be 'Age' or 'iso8601duration'?\n            # biosample_message[\"time_of_collection\"] = time_of_collection\n\n            ppackt_d.get(individual_id).biosamples.append(biosample_message)\n\n        # treatment to medical action\n        for idx, row in tqdm(treatment_df.iterrows(), total=len(treatment_df.index), desc=\"Treatment DF\"):\n            individual_id = row[\"subject_id\"]\n            medical_action_message = make_cda_medicalaction(row)\n            if individual_id not in ppackt_d:\n                raise ValueError(f\"Attempt to enter unknown individual ID from treatment factory: \\\"{individual_id}\\\"\")\n            ppackt_d.get(individual_id).medical_actions.append(medical_action_message)\n\n        # When we get here, we have constructed GA4GH Phenopackets with Individual, Disease, Biospecimen, MedicalAction, and GenomicInterpretations\n        return list(ppackt_d.values())\n</code></pre>"},{"location":"cda/cda_table_importer/#src.oncopacket.cda.CdaTableImporter.get_ga4gh_phenopackets","title":"<code>get_ga4gh_phenopackets(source, **kwargs)</code>","text":"<p>Get a list of GA4GH phenopackets corresponding to the individuals returned by the query passed to the constructor.</p> <p>Returns:</p> Type Description <code>typing.List[PPkt.Phenopacket]  New version of CDA: need to change Q to fetch_rows()</code> <p>A list of GA4GH phenopackets corresponding to the individuals selected by the query passed to the constructor.</p> Source code in <code>src/oncopacket/cda/cda_table_importer.py</code> <pre><code>def get_ga4gh_phenopackets(self, source: dict, **kwargs) -&gt; typing.List[PPkt.Phenopacket]:\n    \"\"\"Get a list of GA4GH phenopackets corresponding to the individuals returned by the query passed to the constructor.\n\n    :returns: A list of GA4GH phenopackets corresponding to the individuals selected by the query passed to the constructor.\n    :rtype: typing.List[PPkt.Phenopacket]\n\n    New version of CDA: need to change Q to fetch_rows()\n    \"\"\"\n\n    if 'cohort_name' in kwargs:\n        cohort_name = kwargs['cohort_name']\n    else:\n        # Format timestamp as a string, for example: 'YYYY-MM-DD HH:MM:SS'\n        ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n        cohort_name = f'cohort-{ts}'\n\n    # Dictionary of phenopackets, keys are the phenopacket ids.\n    ppackt_d = {}\n\n    # First obtain the pandas DataFrames from the CDA tables with rows that correspond to the Query\n    # (MLS 6/18/24) rewriting this to get subject, researchsubject, diagnosis, specimen, and treatment dataframes,\n    # then merge them here to avoid getting researchsubject and subject dataframes multiple times.\n\n    subject_df = self.get_subject_df(source, cohort_name)\n    rsub_df = self.get_researchsubject_df(source, cohort_name)\n    diagnosis_df = self.get_diagnosis_df(source, cohort_name)\n    specimen_df = self.get_specimen_df(source, cohort_name)\n    treatment_df = self.get_treatment_df(source, cohort_name)\n\n    # merge dfs:\n    # can actually just make one merged df with subject_id, researchsubject_id, primary_diagnosis_condition,\n    # primary_diagnosis_site, primary_diagnosis, age_at_diagnosis, stage\n    # loop through it to generate:\n    #  - disease_factory\n    #  - vital_status\n    #  - variants\n    sub_rsub_diag_df = subject_df.merge(rsub_df, on='subject_id', how='outer')\n    sub_rsub_diag_df = sub_rsub_diag_df.merge(diagnosis_df, on='subject_id', how='outer')\n\n    #sub_rsub_diag_df.to_csv(\"sub_rsub_diag_df.txt\", sep='\\t') \n    print(\"merged subject-researchsubject-diagnosis df\")\n    '''\n    Have a problem with patients that have multiple researchsubject IDs with differing primary diagnosis sites\n\n    \tsubject_id\tcause_of_death\tdays_to_birth\tdays_to_death\tethnicity\trace\tsex\tspecies\tvital_status\tresearchsubject_id\tprimary_diagnosis_site\n    0\tTCGA.TCGA-AG-3881\t\t-30467\t&lt;NA&gt;\t\t\tfemale\thuman\tAlive\tphs003155.TCGA-AG-3881\t\n    1\tTCGA.TCGA-AG-3881\t\t-30467\t&lt;NA&gt;\t\t\tfemale\thuman\tAlive\tTCGA-READ.TCGA-AG-3881\t\n    2\tTCGA.TCGA-AG-3881\t\t-30467\t&lt;NA&gt;\t\t\tfemale\thuman\tAlive\ttcga_read.TCGA-AG-3881.RS\trectum\n    '''\n\n    # Now use the CdaFactory classes to transform the information from the DataFrames into\n    # components of the GA4GH Phenopacket Schema\n    # Add these components one at a time to Phenopacket objects.\n\n    print(\"\\nConverting to Phenopackets...\\n\")\n\n    '''\n    required fields:\n    - 'stage'                           # getting from GDC \n    - 'primary_diagnosis_condition'     # diagnosis mapper \n    - 'primary_diagnosis_site'          # uberon mapper\n    - 'primary_diagnosis'               # diagnosis mapper\n    - 'age_at_diagnosis'                # disease term mapper\n    '''\n\n    # Retrieve GA4GH Individual messages\n    for _, row in tqdm(subject_df.iterrows(), total=len(subject_df), desc= \"individual dataframe\"):\n        try:\n            individual_message = self._individual_factory.to_ga4gh(row=row)\n        except ValueError as e:\n            # TODO: decide how to handle depending on your paranoia\n            #\n            pass\n\n        individual_id = individual_message.id\n        ppackt = PPkt.Phenopacket()\n        ppackt.id = f'{cohort_name}-{individual_id}'\n        ppackt.subject.CopyFrom(individual_message)\n        ppackt_d[individual_id] = ppackt\n\n    # get stage dictionary, map to subject ID\n    print(\"Retrieving stage info from GDC...\", end='')\n    stage_dict = self._gdc_service.fetch_stage_dict()\n    print(\"Done!\")\n\n    # remove initial data source label: TCGA.TCGA-4J-AA1J &gt; TCGA-4J-AA1J\n    sub_rsub_diag_df['subject_id_short'] = sub_rsub_diag_df[\"subject_id\"].str.extract(r'^[^\\.]+\\.(.+)', expand=False)\n    sub_rsub_diag_df['stage'] = sub_rsub_diag_df['subject_id_short'].map(stage_dict).fillna(sub_rsub_diag_df['stage'])\n\n    sub_rsub_diag_df['primary_diagnosis'] = sub_rsub_diag_df['primary_diagnosis'].fillna('') # remove nans (not sure why they are there)\n    sub_rsub_diag_df.to_csv('sub_rsub_diag_df.txt', sep='\\t')\n\n\n\n    # Retrieve GA4GH Disease messages\n    for _, row in tqdm(sub_rsub_diag_df.iterrows(), total=len(sub_rsub_diag_df.index), desc=\"creating disease messsages\"):\n\n\n        disease_message = self._disease_factory.to_ga4gh(row)\n        pp = ppackt_d.get(row[\"subject_id\"])\n\n        # Do not add the disease if it is already in the phenopacket.\n        if not any(disease.term.id == disease_message.term.id for disease in pp.diseases):\n            pp.diseases.append(disease_message)\n\n        # need to check if we have the age_at_diagnosis in the phenopacket message\n        for disease in pp.diseases:\n            if not disease.HasField(\"onset\") and disease.term.id == disease_message.term.id and disease_message.HasField(\"onset\"):\n                disease.onset.CopyFrom(disease_message.onset)\n\n        # get vital status from GDC - probably not needed (should be same as subject_df obtained from CDA)\n        # vital_status = self._gdc_service.fetch_vital_status(subj_id)\n        # ppackt_d.get(individual_id).subject.vital_status.CopyFrom(vital_status)\n\n    # Get variant data \n    # -&gt;takes ~15-45 minutes due to API calls to GDC\n    # should sub_rsub_diag_df already be filtered to GDC?\n    sub_rsub_diag_GDC_df = sub_rsub_diag_df[sub_rsub_diag_df['subject_data_source'] == 'GDC']\n\n    for _, row in tqdm(sub_rsub_diag_GDC_df.iterrows(), total=len(sub_rsub_diag_df.index), desc=\"getting variants from GDC\"):\n\n        individual_id = row[\"subject_id\"]\n        # have to strip off the leading name before first period\n        # e.g. TCGA.TCGA-05-4250 -&gt; TCGA-05-4250\n        subj_id = re.sub(\"^[^.]+\\.\", \"\", individual_id)\n\n        # get variants\n        variant_interpretations = self._gdc_service.fetch_variants(subj_id) \n        if len(variant_interpretations) == 0:\n            #print(\"No variants found\")\n            continue\n        #else:\n            #print(\"length variant_interpretations: {}\".format(len(variant_interpretations)))\n\n        # TODO: improve/enhance diagnosis term annotations\n        diagnosis = PPkt.Diagnosis()\n        diagnosis.disease.id = \"NCIT:C3262\"\n        diagnosis.disease.label = \"Neoplasm\"\n\n        for variant in variant_interpretations:\n            genomic_interpretation = PPkt.GenomicInterpretation()\n            genomic_interpretation.subject_or_biosample_id = individual_id\n            genomic_interpretation.interpretation_status = PPkt.GenomicInterpretation.InterpretationStatus.UNKNOWN_STATUS\n            genomic_interpretation.variant_interpretation.CopyFrom(variant)\n\n            diagnosis.genomic_interpretations.append(genomic_interpretation)\n\n        interpretation = PPkt.Interpretation()\n        interpretation.id = f\"{individual_id}-{row['researchsubject_id']}\"\n        interpretation.progress_status = PPkt.Interpretation.ProgressStatus.IN_PROGRESS\n        interpretation.diagnosis.CopyFrom(diagnosis)\n\n        ppackt_d.get(individual_id).interpretations.append(interpretation)\n\n\n    # Retrieve GA4GH Biospecimen messages\n    for idx, row in tqdm(specimen_df.iterrows(),total=len(specimen_df.index), desc=\"specimen/biosample dataframe\"):\n        biosample_message = self._specimen_factory.to_ga4gh(row)\n        individual_id = row[\"subject_id\"]\n        if individual_id not in ppackt_d:\n            raise ValueError(f\"Attempt to enter unknown individual ID from biosample factory: \\\"{individual_id}\\\"\")\n\n        # convert CDA days_to_collection to PPKt time_of_collection\n        #         days_to_collection: number of days from index date to sample collection date\n        #         time_of_collection: Age of subject at time sample was collected\n        if not pd.isna(row['days_to_collection']):\n            days_to_coll_iso = CdaFactory.days_to_iso(int(row[\"days_to_collection\"]))\n\n        # TODO: fix the code below!\n        # this should work if both are pd.Timedelta:\n        # time_of_collection = ppackt_d[individual_id][\"iso8601duration\"] + days_to_coll_iso # should it be 'Age' or 'iso8601duration'?\n        # biosample_message[\"time_of_collection\"] = time_of_collection\n\n        ppackt_d.get(individual_id).biosamples.append(biosample_message)\n\n    # treatment to medical action\n    for idx, row in tqdm(treatment_df.iterrows(), total=len(treatment_df.index), desc=\"Treatment DF\"):\n        individual_id = row[\"subject_id\"]\n        medical_action_message = make_cda_medicalaction(row)\n        if individual_id not in ppackt_d:\n            raise ValueError(f\"Attempt to enter unknown individual ID from treatment factory: \\\"{individual_id}\\\"\")\n        ppackt_d.get(individual_id).medical_actions.append(medical_action_message)\n\n    # When we get here, we have constructed GA4GH Phenopackets with Individual, Disease, Biospecimen, MedicalAction, and GenomicInterpretations\n    return list(ppackt_d.values())\n</code></pre>"},{"location":"cda/cda_table_importer/#src.oncopacket.cda.CdaTableImporter.get_specimen_df","title":"<code>get_specimen_df(q, cohort_name)</code>","text":"<p>Retrieve the subject dataframe from CDA</p> <p>This method uses the Query that was passed to the constructor to retrieve data from the CDA subject table</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pandas DataFrame that corresponds to the CDA subject table.</p> Source code in <code>src/oncopacket/cda/cda_table_importer.py</code> <pre><code>def get_specimen_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n    \"\"\"Retrieve the subject dataframe from CDA\n\n    This method uses the Query that was passed to the constructor to retrieve data from the CDA subject table\n\n    :raises: raises an exception if the query object was not properly initialized\n    :returns: pandas DataFrame that corresponds to the CDA subject table.\n    :rtype: pd.DataFrame\n    \"\"\"\n    print(\"\\nGetting specimen df...\")\n    #specimen_callable = lambda: q.specimen.run(page_size=self._page_size).get_all().to_dataframe()\n    specimen_callable = lambda: fetch_rows( table='specimen', **q, add_columns=['subject_id'] )\n    specimen_df = self._get_cda_df(specimen_callable, f\"{cohort_name}_specimen_df.pkl\")\n    #specimen_df.to_csv('specimen_df.txt', sep='\\t')\n    return specimen_df\n</code></pre>"},{"location":"cda/cda_table_importer/#src.oncopacket.cda.CdaTableImporter.get_subject_df","title":"<code>get_subject_df(q, cohort_name)</code>","text":"<p>Retrieve the subject dataframe from CDA</p> <p>This method uses the Query that was passed to the constructor to retrieve data from the CDA subject table</p> <p>Note: 1/31/25.  The new version of CDA is returning all records that have a subject that is in GDC (essentially all of them),  so despite the data_source='GDC', we get back rows from other data commons.    </p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pandas DataFrame that corresponds to the CDA subject table.</p> Source code in <code>src/oncopacket/cda/cda_table_importer.py</code> <pre><code>def get_subject_df(self, q: dict, cohort_name: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Retrieve the subject dataframe from CDA\n\n    This method uses the Query that was passed to the constructor to retrieve data from the CDA subject table\n\n    Note: 1/31/25.  The new version of CDA is returning all records that have a subject that is in GDC (essentially all of them), \n    so despite the data_source='GDC', we get back rows from other data commons.    \n\n    :raises: ValueError if no rows are returned\n    :returns: pandas DataFrame that corresponds to the CDA subject table.\n    :rtype: pd.DataFrame\n    \"\"\"\n    print(\"\\nGetting subject df...\")\n\n    # Define the callable to fetch the subject rows\n    callable = lambda: fetch_rows(table='subject', **q, provenance=True)\n\n    # Get the subject DataFrame (or load from cache if available)\n    subject_df = self._get_cda_df(callable, f\"{cohort_name}_individual_df.pkl\")\n\n    # Check if the returned DataFrame is empty\n    if subject_df is None or subject_df.empty:\n        message = f\"No subject rows returned for cohort '{cohort_name}'. \" \\\n                  f\"Please check your query parameters or data source.\"\n        print(f\"Error: {message}\")\n        # Fail gracefully by raising an exception with a descriptive message.\n        raise ValueError(message)\n\n    # Process the DataFrame further only if it has data\n    subject_df = subject_df.drop(columns=['subject_data_source_id'], axis=1)\n    subject_df = subject_df.drop_duplicates()\n\n    # filter here for data source (TODO: deal with multiple sources)\n    if 'data_source' in q.keys():\n        subject_df = subject_df[subject_df['subject_data_source'] == q['data_source']]\n    #print(\"subject_df filtered dim: \", subject_df.shape)\n    #subject_df.to_csv('subject_df.txt', sep='\\t')\n    print(\"obtained subject_df\")\n\n    return subject_df\n</code></pre>"},{"location":"explanations/cda_disease/","title":"CDA Disease","text":"<p>We extract information about the disease diagnosis from two CDA tables, <code>diagnosis</code> and <code>researchsubject</code>. We first summarize the tables and then outline our ETL strategy.</p>"},{"location":"explanations/cda_disease/#diagnosis","title":"diagnosis","text":"Column Example Explanation diagnosis_id CGCI-HTMCP-CC.HTMCP-03-06-02424.HTMCP-03-06-02424_diagnosis y diagnosis_identifier see below y primary_diagnosis Squamous cell carcinoma, keratinizing, NOS y age_at_diagnosis 13085.0 y morphology 8071/3 y stage None y grade G3 y method_of_diagnosis Biopsy y subject_id CGCI.HTMCP-03-06-02424 y researchsubject_id CGCI-HTMCP-CC.HTMCP-03-06-02424 y <p>The fields of the table have the following meaning.</p> <ul> <li>diagnosis_id Question: It seems as if this identifier has some syntex of meaning or is it random?</li> <li>diagnosis_identifier Question: This field seems to have a lot of structure. How is it used in CDA and is there documentation on how to interpret it? This field has the following structure. <pre><code>[{'system': 'GDC',\n  'field_name': 'case.diagnoses.diagnosis_id',\n  'value': '06af070e-aad4-5b2d-a693-b6ccfe93985a'},\n {'system': 'GDC',\n  'field_name': 'case.diagnoses.submitter_id',\n  'value': 'HTMCP-03-06-02424_diagnosis'}]\n</code></pre></li> <li>primary_diagnosis This field represents the main cancer diagnosis of this individual</li> <li>age_at_diagnosis This field represents the number of days of life of the individual on the day during which the cancer diagnosis was made.</li> <li>morphology Entries such as <code>8071/3</code> are ICD-O codes. TODO - translate into ontology codes.</li> <li>stage Cancer stage.</li> <li>grade Cancer grade. Note that in many tables there are strings such as G3. NCIT has more detailed terms, but we think it best to stick to the top level, and possible consider postcomposition to represent specific stage systems.</li> <li>method_of_diagnosis This corresponds to</li> <li>subject_id Identifier for the individual being investigated</li> <li>researchsubject_id Identifier for the researchsubject (which can be a sample or an individaul - Question: where is this documented?)</li> </ul>"},{"location":"explanations/cda_disease/#researchsubject","title":"researchsubject","text":"Column Example Explanation researchsubject_id CPTAC-3.C3L-00563 y researchsubject_identifier see below y member_of_research_project CPTAC-3 y primary_diagnosis_condition Adenomas and Adenocarcinomas y primary_diagnosis_site Uterus, NOS y subject_id CPTAC.C3L-00563 y <ul> <li>researchsubject_id xyz</li> <li> <p>researchsubject_identifier Question: How do we interpret this kind of structure: <pre><code>[{'system': 'GDC',\n  'field_name': 'case.case_id',\n  'value': '2b1894fb-b168-42ca-942f-a5def0bb8309'},\n {'system': 'GDC', 'field_name': 'case.submitter_id', 'value': 'C3L-00563'}]\n</code></pre></p> </li> <li> <p>member_of_research_project Question: Where do we get more information about the research projects? What informationis available?</p> </li> <li>primary_diagnosis_condition Question: This seems to be duplicative with the field <code>primary_diagnosis</code> in the diagnosis table. What is the difference?</li> <li>primary_diagnosis_site Todo - we can map this to uberon</li> <li>subject_id This relates to the subject_id in other tables.</li> </ul>"},{"location":"explanations/cda_disease/#mapping-strategy","title":"Mapping strategy","text":"<p>We merge the diagnosis and researchsubject tables to retrieve all needed information about the disease diagnosis.</p> Merging diagnosis and researchsubject via the researchsubject_id<pre><code>merged_df = pd.merge(diagnosis_df,\n                    rsub_df,\n                    left_on='researchsubject_id',\n                    right_on='researchsubject_id',\n                    suffixes=[\"_di\", \"_rs\"])\n</code></pre>"},{"location":"explanations/cda_mutation/","title":"CDA Mutation","text":"<p>We extract information about variants from the CDA table <code>mutation</code>. We first summarize the table and then outline our ETL strategy.</p> Column Example Explanation project_short_name TCGA-CESC case_barcode TCGA-C5-A1MI cda_subject_id TCGA.TCGA-C5-A1MI primary_site Cervix uteri Hugo_Symbol IGSF9B Entrez_Gene_Id 22997 Center BI NCBI_Build GRCh38 Chromosome chr11 Start_Position 133921225 End_Position 133921225 Strand + Variant_Classification Missense_Mutation Variant_Type SNP Reference_Allele C Tumor_Seq_Allele1 C Tumor_Seq_Allele2 T dbSNP_RS rs771150072 dbSNP_Val_Status Tumor_Aliquot_Barcode TCGA-C5-A1MI-01A-11D-A14W-08 Matched_Norm_Aliquot_Barcode TCGA-C5-A1MI-10A-01D-A14W-08 Match_Norm_Seq_Allele1 Match_Norm_Seq_Allele2 Tumor_Validation_Allele1 Tumor_Validation_Allele2 Match_Norm_Validation_Allele1 Match_Norm_Validation_Allele2 Verification_Status Validation_Status Mutation_Status Somatic Sequencing_Phase Sequence_Source Validation_Method Score BAM_File Sequencer Tumor_Aliquot_UUID 497c20f0-8a42-4d20-abdc-0415982ebb9f Matched_Norm_Aliquot_UUID a3d0503b-baac-4f83-9182-be7b4154c61d HGVSc c.2500G&gt;A HGVSp p.Val834Met HGVSp_Short p.V834M Transcript_ID ENST00000321016 Exon_Number 18/19 t_depth 64 t_ref_count 43 t_alt_count 20 n_depth 88 n_ref_count n_alt_count all_effects IGSF9B,missense_variant,p.V834M,ENST00000533871,NM_001277285.4,c.2500G&gt;A,MODERATE,YES,deleterious(0),probably_damaging(1),-1;IGSF9B,missense_variant,p.V834M,ENST00000321016,,c.2500G&gt;A,MODERATE,,deleterious(0.01),probably_damaging(0.988),-1;IGSF9B,downstream_gene_variant,,ENST00000527648,,,MODIFIER,,,,-1 Allele T Gene ENSG00000080854 Feature ENST00000321016 Feature_type Transcript One_Consequence missense_variant Consequence missense_variant cDNA_position 2500/4050 Protein_position 834/1349 Amino_acids V/M Codons Gtg/Atg Existing_variation rs771150072;COSV58068494 DISTANCE TRANSCRIPT_STRAND -1 SYMBOL IGSF9B SYMBOL_SOURCE HGNC HGNC_ID HGNC:32326 BIOTYPE protein_coding CANONICAL CCDS ENSP ENSP00000317980 SWISSPROT Q9UPX0.150 TREMBL UNIPARC UPI0001545E3E UNIPROT_ISOFORM Q9UPX0-1 RefSeq MANE APPRIS FLAGS SIFT deleterious(0.01) PolyPhen probably_damaging(0.988) EXON 18/19 INTRON DOMAINS PANTHER:PTHR12231;PANTHER:PTHR12231:SF240;Low_complexity_(Seg):seg ThousG_AF ThousG_AFR_AF ThousG_AMR_AF ThousG_EAS_AF ThousG_EUR_AF ThousG_SAS_AF ESP_AA_AF ESP_EA_AF gnomAD_AF 1.216e-05 gnomAD_AFR_AF gnomAD_AMR_AF gnomAD_ASJ_AF gnomAD_EAS_AF gnomAD_FIN_AF gnomAD_NFE_AF gnomAD_OTH_AF gnomAD_SAS_AF MAX_AF 9.968e-05 MAX_AF_POPS 3.278e-05 gnomAD_non_cancer_AF gnomAD_non_cancer_AFR_AF gnomAD_non_cancer_AMI_AF gnomAD_non_cancer_AMR_AF gnomAD_non_cancer_ASJ_AF gnomAD_non_cancer_EAS_AF gnomAD_non_cancer_FIN_AF gnomAD_non_cancer_MID_AF gnomAD_non_cancer_NFE_AF gnomAD_non_cancer_OTH_AF gnomAD_non_cancer_SAS_AF gnomAD_non_cancer_MAX_AF_adj gnomAD_non_cancer_MAX_AF_POPS_adj CLIN_SIG SOMATIC 0;1 PUBMED TRANSCRIPTION_FACTORS MOTIF_NAME MOTIF_POS HIGH_INF_POS MOTIF_SCORE_CHANGE miRNA IMPACT MODERATE PICK VARIANT_CLASS SNV TSL 5 HGVS_OFFSET PHENO 0;1 GENE_PHENO CONTEXT GGCCACGCTGT tumor_submitter_uuid 8c3559db-155f-42d3-9a73-38d5610f74b5 normal_submitter_uuid 59778b5f-335a-471e-abb2-6dde0b5d7fe7 case_id 941f75a1-fea4-4539-ba69-60bb11608f6d GDC_FILTER COSMIC COSM376595;COSM376596 hotspot False RNA_Support Unknown RNA_depth RNA_ref_count RNA_alt_count callers muse;mutect2;varscan2 file_gdc_id 3fd5afe7-9e69-4ea8-ab01-80e41783d795 muse Yes mutect2 Yes pindel No varscan2 Yes sample_barcode_tumor TCGA-C5-A1MI-01A sample_barcode_normal TCGA-C5-A1MI-10A aliquot_barcode_tumor TCGA-C5-A1MI-01A-11D-A14W-08 aliquot_barcode_normal TCGA-C5-A1MI-10A-01D-A14W-08 <p>We will use only a few fields for extracting data for the phenopacket. These fields are explained below.</p>"},{"location":"explanations/new_cda_api/","title":"Using the Cancer Data Aggregator (CDA) API","text":"<p>This document explains how Oncopacket interacts with the Cancer Data Aggregator (CDA) API to extract cancer research data and transform it into GA4GH Phenopackets.</p>"},{"location":"explanations/new_cda_api/#overview-of-cda-api-integration","title":"Overview of CDA API Integration","text":"<p>Oncopacket utilizes the CDA Python library (<code>cdapython</code>) to access data from the NCI Cancer Research Data Commons. The CDA provides a unified API that aggregates data from multiple NCI data repositories, including:</p> <ul> <li>Genomic Data Commons (GDC)</li> <li>Proteomic Data Commons (PDC)</li> <li>Imaging Data Commons (IDC)</li> <li>Clinical Trial Data Commons (CTDC)</li> </ul>"},{"location":"explanations/new_cda_api/#accessing-specific-data-elements","title":"Accessing Specific Data Elements","text":""},{"location":"explanations/new_cda_api/#cancer-stage-information","title":"Cancer Stage Information","text":"<p>While CDA's <code>diagnoses.tumor_stage</code> endpoint doesn't return data, Oncopacket directly accesses GDC API endpoints for cancer staging information:</p> <ul> <li><code>diagnoses.ajcc_pathologic_stage</code></li> <li><code>diagnoses.ajcc_clinical_stage</code></li> <li><code>diagnoses.ann_arbor_pathologic_stage</code></li> <li><code>diagnoses.ann_arbor_clinical_stage</code></li> </ul> <p>These endpoints are constructed based on the GDC schema document: https://github.com/NCI-GDC/gdcdictionary/blob/develop/src/gdcdictionary/schemas/diagnosis.yaml</p>"},{"location":"explanations/new_cda_api/#vital-status-information","title":"Vital Status Information","text":"<p>For vital status, Oncopacket uses the <code>demographic.vital_status</code> endpoint.</p>"},{"location":"explanations/new_cda_api/#data-transformation-process","title":"Data Transformation Process","text":"<ol> <li>Extract: Fetch data from CDA tables</li> <li>Transform: Convert CDA data models to Oncopacket model classes</li> <li>Map: Use ontology mappers to standardize terminology</li> <li>Load: Populate GA4GH Phenopacket structures</li> </ol> <p>The CDA factory classes in Oncopacket handle these transformation processes, creating a streamlined pipeline from CDA data to standardized phenopackets.</p>"},{"location":"explanations/new_cda_api/#updates-and-changes","title":"Updates and Changes","text":"<p>Note: This documentation reflects the CDA API implementation as of April 10, 2024. As the CDA API evolves, Oncopacket's interaction with it may change.</p>"},{"location":"model/","title":"Oncopacket: Model Module","text":"<p>The model module of Oncopacket contains data models that represent cancer patient data.  These models can be constructed with data from various upstream sources and then exported in GA4GH Phenopacket format.</p>"},{"location":"model/#core-classes","title":"Core Classes","text":"<p>The model module includes several key classes:</p>"},{"location":"model/#opindividual","title":"OpIndividual","text":"<p>The <code>OpIndividual</code> class represents a cancer patient, with demographic information, disease diagnoses, biosamples, and genetic variants.</p> <p>API Documentation for OpIndividual</p>"},{"location":"model/#opdisease","title":"OpDisease","text":"<p>The <code>OpDisease</code> class represents cancer diagnoses, including cancer type, stage, grade, and other diagnostic information.</p>"},{"location":"model/#opmutation","title":"OpMutation","text":"<p>The <code>OpMutation</code> class represents genetic mutations/variants found in a patient's tumor samples.</p>"},{"location":"model/#usage-example","title":"Usage Example","text":"<pre><code>from oncopacket.model import OpIndividual\nimport phenopackets as PPkt\n\n# Create vital status object\nvital_status = PPkt.VitalStatus()\nvital_status.status = PPkt.VitalStatus.ALIVE\n\n# Create an individual\nindividual = OpIndividual(\n    id=\"TCGA-12345\",\n    sex=\"FEMALE\",\n    iso8601duration=\"P65Y\",  # 65 years old\n    vital_status=vital_status\n)\n\n# Convert to GA4GH Phenopacket Individual\nga4gh_individual = individual.to_ga4gh()\n</code></pre> <p>Note that the <code>to_ga4gh()</code> method only converts the individual information to a GA4GH format. For creating complete phenopackets with disease and mutation information, you should use the factory classes provided in the CDA module.</p>"},{"location":"model/#integration-with-cda","title":"Integration with CDA","text":"<p>The model classes are populated by the factory classes in the CDA module, which  extract data from the Cancer Data Aggregator API and convert it to the appropriate  model objects.</p>"},{"location":"model/op_individual/","title":"OpIndividual","text":"<p>               Bases: <code>OpMessage</code></p> <p>This class represents the individual or patient who is the subject of the phenopacket. It provides a DTO-like object to hold data that should be instantiated by factory methods corresponding to the data source. THe class can generate a GA4GH Phenopakcet Schema Individual message.</p> <p>Note that we assume the species is always human, so taxonomy is always set to 9606 Homo sapiens</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>the individual identifier (application-specific)</p> required <code>alternate_ids</code> <code>list</code> <p>list of alternative identifiers, optional</p> <code>[]</code> <code>date_of_birth</code> <code>timestamp, optional</code> <p>date of birth of the individual (optional, should not be used without data privacy protection)</p> <code>None</code> <code>iso8601duration</code> <code>str</code> <p>age represented as an ISO 8601 Period, e.g., P42Y5M would be 42 years and 5 months</p> <code>None</code> <code>vital_status</code> <code>PPkt.VitalStatus</code> <p>An object representing the Vital status of the individual, optional</p> <code>None</code> <code>karyotypic_sex</code> <p>the chromosomal sex (karyotypic sex), of the individual, e.g., XY or XX or XXY, optional</p> <code>None</code> <code>gender</code> <p>the self-described gender of the individual, optional</p> <code>None</code> Source code in <code>src/oncopacket/model/op_Individual.py</code> <pre><code>class OpIndividual(OpMessage):\n    \"\"\"\n    This class represents the individual or patient who is the subject of the phenopacket.\n    It provides a DTO-like object to hold data that should be instantiated by factory methods\n    corresponding to the data source. THe class can generate a GA4GH Phenopakcet Schema Individual message.\n\n    Note that we assume the species is always human, so taxonomy is always set to\n    9606 Homo sapiens\n\n    :param id: the individual identifier (application-specific)\n    :type id: str\n    :param alternate_ids: list of alternative identifiers, optional\n    :type alternate_ids: list\n    :param date_of_birth: date of birth of the individual (optional, should not be used without data privacy protection)\n    :type date_of_birth: timestamp, optional\n    :param iso8601duration: age represented as an ISO 8601 Period, e.g., P42Y5M would be 42 years and 5 months\n    :type iso8601duration: str\n    :param vital_status: An object representing the Vital status of the individual, optional\n    :type vital_status: PPkt.VitalStatus\n    :param karyotypic_sex: the chromosomal sex (karyotypic sex), of the individual, e.g., XY or XX or XXY, optional\n    :param karyotypic_sex: str\n    :param gender: the self-described gender of the individual, optional\n\n    \"\"\"\n    def __init__(self, id,\n                alternate_ids = [],\n                date_of_birth=None,\n                iso8601duration=None,\n                vital_status=None,\n                sex=None,\n                karyotypic_sex=None,\n                gender=None) -&gt; None:\n        \"\"\"Constructor method\n        \"\"\"\n        self._id = id\n        # todo add check for date_of_birth, leaving out for now\n        self._iso8601duration = iso8601duration\n        male_sex = {\"m\", \"male\"}\n        female_sex = {\"f\",  \"female\",}\n        if sex.lower() in male_sex:\n            self._sex = PPkt.MALE\n        elif sex.lower() in female_sex:\n            self._sex = PPkt.FEMALE\n        else:\n            self._sex = PPkt.UNKNOWN_SEX\n\n        self._taxonomy = PPkt.OntologyClass()\n        self._taxonomy.id = \"NCBITaxon:9606\"\n        self._taxonomy.label = \"Homo sapiens\"\n\n        self._vital_status = vital_status\n\n\n    def to_ga4gh(self) -&gt; PPkt.Individual:\n        \"\"\"Transform the data in the onject into a GA4GH Phenopacket Individual\n        :return: An message corresponding to the GA4GH Phenopacket Individual\n        :rtype: PPkt.Individual\n        \"\"\"\n        individual =  PPkt.Individual()\n        individual.id = self._id\n        if self._iso8601duration is not None:\n            individual.time_at_last_encounter.age.iso8601duration = self._iso8601duration\n        individual.sex = self._sex\n        if self._taxonomy is not None:\n            individual.taxonomy.CopyFrom(self._taxonomy)\n        if self._vital_status is not None:\n            individual.vital_status.status = self._vital_status.status\n        return individual\n</code></pre>"},{"location":"model/op_individual/#src.oncopacket.model.OpIndividual.__init__","title":"<code>__init__(id, alternate_ids=[], date_of_birth=None, iso8601duration=None, vital_status=None, sex=None, karyotypic_sex=None, gender=None)</code>","text":"<p>Constructor method</p> Source code in <code>src/oncopacket/model/op_Individual.py</code> <pre><code>def __init__(self, id,\n            alternate_ids = [],\n            date_of_birth=None,\n            iso8601duration=None,\n            vital_status=None,\n            sex=None,\n            karyotypic_sex=None,\n            gender=None) -&gt; None:\n    \"\"\"Constructor method\n    \"\"\"\n    self._id = id\n    # todo add check for date_of_birth, leaving out for now\n    self._iso8601duration = iso8601duration\n    male_sex = {\"m\", \"male\"}\n    female_sex = {\"f\",  \"female\",}\n    if sex.lower() in male_sex:\n        self._sex = PPkt.MALE\n    elif sex.lower() in female_sex:\n        self._sex = PPkt.FEMALE\n    else:\n        self._sex = PPkt.UNKNOWN_SEX\n\n    self._taxonomy = PPkt.OntologyClass()\n    self._taxonomy.id = \"NCBITaxon:9606\"\n    self._taxonomy.label = \"Homo sapiens\"\n\n    self._vital_status = vital_status\n</code></pre>"},{"location":"model/op_individual/#src.oncopacket.model.OpIndividual.to_ga4gh","title":"<code>to_ga4gh()</code>","text":"<p>Transform the data in the onject into a GA4GH Phenopacket Individual</p> <p>Returns:</p> Type Description <code>PPkt.Individual</code> <p>An message corresponding to the GA4GH Phenopacket Individual</p> Source code in <code>src/oncopacket/model/op_Individual.py</code> <pre><code>def to_ga4gh(self) -&gt; PPkt.Individual:\n    \"\"\"Transform the data in the onject into a GA4GH Phenopacket Individual\n    :return: An message corresponding to the GA4GH Phenopacket Individual\n    :rtype: PPkt.Individual\n    \"\"\"\n    individual =  PPkt.Individual()\n    individual.id = self._id\n    if self._iso8601duration is not None:\n        individual.time_at_last_encounter.age.iso8601duration = self._iso8601duration\n    individual.sex = self._sex\n    if self._taxonomy is not None:\n        individual.taxonomy.CopyFrom(self._taxonomy)\n    if self._vital_status is not None:\n        individual.vital_status.status = self._vital_status.status\n    return individual\n</code></pre>"}]}